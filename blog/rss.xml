<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>OpenKruise Blog</title>
        <link>https://openkruise.io/blog</link>
        <description>OpenKruise Blog</description>
        <lastBuildDate>Mon, 13 Dec 2021 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[OpenKruise v1.0, Reaching New Peaks of application automation]]></title>
            <link>https://openkruise.io/blog/openkruise-1.0</link>
            <guid>openkruise-1.0</guid>
            <pubDate>Mon, 13 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[We’re pleased to announce the release of Kubernetes 1.0, which is a CNCF Sandbox level project.]]></description>
            <content:encoded><![CDATA[<p>We’re pleased to announce the release of Kubernetes 1.0, which is a CNCF Sandbox level project.</p><p><a href="https://openkruise.io">OpenKruise</a> is an extended component suite for Kubernetes, which mainly focuses on application automations, such as deployment, upgrade, ops and availability protection. Mostly features provided by OpenKruise are built primarily based on CRD extensions. They can work in pure Kubernetes clusters without any other dependences.</p><p><img src="/img/blog/2021-12-13-release-1.0/features-en.png" alt="openkruise-features|center|450x400"/></p><p>Overall, OpenKruise currently provides features in these areas:</p><ul><li><strong>Application workloads</strong>: Enhanced strategies of deploy and upgrade for stateless/stateful/daemon applications, such as in-place update, canary/flowing upgrade.</li><li><strong>Sidecar container management</strong>: supports to define sidecar container alone, which means it can inject sidecar containers, upgrade them with no effect on application containers and even hot upgrade.</li><li><strong>Enhanced operations</strong>: such as restart containers in-place, pre-download images on specific nodes, keep containers launch priority in a Pod, distribute one resource to multiple namespaces.</li><li><strong>Application availability protection</strong>: protect availability for applications that deployed in Kubernetes.</li></ul><h2>What&#x27;s new?</h2><h3>1. InPlace Update for environments</h3><p><em>Author: <a href="https://github.com/FillZpp">@FillZpp</a></em></p><p>OpenKruise has supported <strong>InPlace Update</strong> since very early version, mostly for workloads like CloneSet and Advanced StatefulSet. Comparing to recreate Pods during upgrade, in-place update only has to modify the fields in existing Pods.</p><p><img src="/img/docs/core-concepts/inplace-update-comparation.png" alt="inplace-update-comparation|center|450x400"/></p><p>As the picture shows above, we only modify the <code>image</code> field in Pod during in-place update. So that:</p><ul><li>Avoid additional cost of <em>scheduling</em>, <em>allocating IP</em>, <em>allocating and mounting volumes</em>.</li><li>Faster image pulling, because of we can re-use most of image layers pulled by the old image and only to pull several new layers.</li><li>When a container is in-place updating, the other containers in Pod will not be affected and remain running.</li></ul><p>However, OpenKruise only supports to in-place update <code>image</code> field in Pod and has to recreate Pods if other fields need to update. All the way through, more and more users hope OpenKruise could support in-place update more fields such as <code>env</code> -- which is hard to implement, for it is limited by kube-apiserver.</p><p>After our unremitting efforts, OpenKruise finally support in-place update environments via Downward API since version v1.0. Take the CloneSet YAML below as an example, user has to set the configuration in annotation and write a env from it. After that, he just needs to modify the annotation value when changing the configuration. Kruise will restart all containers with env from the annotation in such Pod to enable the new configuration.</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: CloneSet
metadata:
  ...
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        app-config: &quot;... the real env value ...&quot;
    spec:
      containers:
      - name: app
        env:
        - name: APP_CONFIG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations[&#x27;app-config&#x27;]
  updateStrategy:
    type: InPlaceIfPossible
</code></pre><p><em>At the same time, we have removed the limit of <code>imageID</code> for in-place update, which means you can update a new image with the same imageID to the old image.</em></p><p>For more details please read <a href="/docs/core-concepts/inplace-update">documentation</a>.</p><h3>2. Distribute resources over multiple namespaces</h3><p><em>Author: <a href="https://github.com/veophi">@veophi</a></em></p><p>For the scenario, where the namespace-scoped resources such as Secret and ConfigMap need to be distributed or synchronized to different namespaces, the native k8s currently only supports manual distribution and synchronization by users one-by-one, which is very inconvenient. </p><p>Typical examples: </p><ul><li>When users want to use the imagePullSecrets capability of SidecarSet, they must repeatedly create corresponding Secrets in relevant namespaces, and ensure the correctness and consistency of these Secret configurations;</li><li>When users want to configure some common environment variables, they probably need to distribute ConfigMaps to multiple namespaces, and the subsequent modifications of these ConfigMaps might require synchronization among these namespaces.</li></ul><p>Therefore, in the face of these scenarios that require the resource distribution and <strong>continuously synchronization across namespaces</strong>, we provide a tool, namely <strong>ResourceDistribution</strong>, to do this automatically. </p><p>Currently, ResourceDistribution supports the two kind resources --- <strong>Secret &amp; ConfigMap</strong>. </p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: ResourceDistribution
metadata:
  name: sample
spec:
  resource:
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: game-demo
    data:
      ...
  targets:
    namespaceLabelSelector:
      ...
    # or includedNamespaces, excludedNamespaces
</code></pre><p>So you can see ResourceDistribution is a kind of <strong>cluster-scoped CRD</strong>, which is mainly composed of two fields: <strong><code>resource</code> and <code>targets</code></strong>.</p><ul><li><code>resource</code> is a <strong>complete</strong> and <strong>correct</strong> resource structure in YAML style.</li><li><code>targets</code> indicates the target namespaces that the resource should be distributed into.</li></ul><p>For more details please read <a href="/docs/user-manuals/resourcedistribution">documentation</a>.</p><h3>3. Container launch priority</h3><p><em>Author: <a href="https://github.com/Concurrensee">@Concurrensee</a></em></p><p>Containers in a same Pod in it might have dependence, which means the application in one container runs depending on another container. For example:</p><ol><li>Container A has to start first. Container B can start only if A is already running.</li><li>Container B has to exit first. Container A can stop only if B has already exited.</li></ol><p>Currently, the sequences of containers start and stop are controlled by Kubelet.
Kubernetes used to have a KEP, which plans to add a type field for container to identify the priority of start and stop. However, it has been refused because of sig-node thought it may bring a huge change to code.</p><p>So OpenKruise provides a feature named <strong>Container Launch Priority</strong>, which helps user control the sequence of containers start in a Pod.</p><ol><li>User only has to put the annotation <code>apps.kruise.io/container-launch-priority: Ordered</code> in a Pod, then Kruise will ensure all containers in this Pod should be started by the sequence of <code>pod.spec.containers</code> list.</li><li>If you want to customize the launch sequence, you can add <code>KRUISE_CONTAINER_PRIORITY</code> environment in container. The range of the value is <code>[-2147483647, 2147483647]</code>. The container with higher priority will be guaranteed to start before the others with lower priority.</li></ol><p>For more details please read <a href="/docs/user-manuals/containerlaunchpriority">documentation</a>.</p><h3>4. <code>kubectl-kruise</code> commandline tool</h3><p><em>Author: <a href="https://github.com/hantmac">@hantmac</a></em></p><p>OpenKruise used to provide SDK like <code>kruise-api</code> and <code>client-java</code> for some programming languages, which can be imported into users&#x27; projects. On the other hand, some users also need to operate the workload resources with commandline in test environment.</p><p>However, the <code>rollout</code>, <code>set image</code> commands in original <code>kubectl</code> can only work for built-in workloads, such as Deployment and StatefulSet.</p><p>So, OpenKruise now provide a commandline tool named <code>kubectl-kruise</code>, which is a standard plugin of <code>kubectl</code> and can work for OpenKruise workload types.</p><pre><code class="language-bash"># rollout undo cloneset
$ kubectl kruise rollout undo cloneset/nginx

#  rollout status advanced statefulset
$ kubectl kruise rollout status statefulsets.apps.kruise.io/sts-demo

# set image of a cloneset
$ kubectl kruise set image cloneset/nginx busybox=busybox nginx=nginx:1.9.1
</code></pre><p>For more details please read <a href="/docs/cli-tool/kubectl-plugin">documentation</a>.</p><h3>5. Other changes</h3><p><strong>CloneSet:</strong></p><ul><li>Add <code>maxUnavailable</code> field in <code>scaleStrategy</code> to support rate limiting of scaling up.</li><li>Mark revision stable when all pods updated to it, won&#x27;t wait all pods to be ready.</li></ul><p><strong>WorkloadSpread:</strong></p><ul><li>Manage the pods that have created before WorkloadSpread.</li><li>Optimize the update and retry logic for webhook injection.</li></ul><p><strong>Advanced DaemonSet:</strong></p><ul><li>Support in-place update Daemon Pod.</li><li>Support progressive annotation to control if pods creation should be limited by partition.</li></ul><p><strong>SidecarSet:</strong></p><ul><li>Fix SidecarSet filter active pods.</li><li>Add <code>SourceContainerNameFrom</code> and <code>EnvNames</code> fields in <code>transferenv</code> to make the container name flexible and the list shorter.</li></ul><p><strong>PodUnavailableBudget:</strong></p><ul><li>Add no pub-protection annotation to skip validation for the specific Pod.</li><li>PodUnavailableBudget controller watches workload replicas changed.</li></ul><p><strong>NodeImage:</strong></p><ul><li>Add <code>--nodeimage-creation-delay</code> flag to delay NodeImage creation after Node ready.</li></ul><p><strong>UnitedDeployment:</strong></p><ul><li>Fix pod NodeSelectorTerms length 0 when UnitedDeployment NodeSelectorTerms is nil.</li></ul><p><strong>Other optimization:</strong></p><ul><li>kruise-daemon list and watch pods using protobuf.</li><li>Export cache resync args and defaults to be 0 in chart value.</li><li>Fix http checker reloading after webhook certs updated.</li><li>Generate CRDs with original controller-tools and markers.</li></ul><h2>Get Involved</h2><p>Welcome to get involved with OpenKruise by joining us in Github/Slack/DingTalk/WeChat.
Have something you’d like to broadcast to our community?
Share your voice at our <a href="https://shimo.im/docs/gXqmeQOYBehZ4vqo">Bi-weekly community meeting (Chinese)</a>, or through the channels below:</p><ul><li>Join the community on <a href="https://kubernetes.slack.com/channels/openkruise">Slack</a> (English).</li><li>Join the community on DingTalk: Search GroupID <code>23330762</code> (Chinese).</li><li>Join the community on WeChat: Search User <code>openkruise</code> and let the robot invite you (Chinese).</li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WorkloadSpread - Interpretation for OpenKruise v0.10.0 new feature]]></title>
            <link>https://openkruise.io/blog/workloadspread</link>
            <guid>workloadspread</guid>
            <pubDate>Wed, 22 Sep 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[Background]]></description>
            <content:encoded><![CDATA[<h2>Background</h2><p>Deploying an application in different zones, different hardware types, and even different clusters and cloud vendors is becoming a very common requirement with the development of cloud native techniques.
For examples, these are some cases:</p><ol><li>Cases about disaster tolerant:</li></ol><ul><li>Application pods is scattered according to the nodes to avoid stacking.</li><li>Application pods is scattered according to available zones.</li><li>Different nodes/zones/domains require different scale of pods.</li></ul><ol start="2"><li>Cases about cost control:</li></ol><ul><li>People deploy an applications preferentially to their own resource pool, and then deployed to elastic resource pool, such as ECI on Aliyun and Fragate on AWS, when own resources are insufficient. When shrinking, the elastic node is preferred to shrink to save cost.</li></ul><p>In the most of the cases, people always split their application into multiple workloads (such as several <code>Deployment</code>) to deploy. However，this solution often requires manual management by SRE team, or a deeply customized PAAS to support the careful management of multiple workloads for this one application.</p><p>In order to solve this problem, WorkloadSpread feature has been proposed in version v0.10.0 OpenKruise. It can support multi-kind of workloads, such as <code>Deployment</code>, <code>Replicaset</code>, <code>Job</code>, and <code>Cloneset</code>, to manage the partition deployment or elastic scaling. The application scenario and implementation principle of WorkloadSpread will be introduced in detail below to help users better understand this feature.</p><hr/><h2>Introduction</h2><p>More details about WorkloadSpread can be found in <a href="https://openkruise.io/docs/user-manuals/workloadspread">Offical Document</a>. </p><p>In short, WorkloadSpread can distribute pods of a workload to different types of nodes according to certain rules, so as to meet the above fragmentation and elasticity scenarios. WorkloadSpread is non-invasive, &quot;plug and play&quot;, and can be effective for stock workloads.</p><hr/><h2>Comparison with related works</h2><p>Let&#x27;s make a simple comparison with some related works in the community.</p><h3>「1」Pod Topology Spread Constrains</h3><p><a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">Pod topology spread constraints</a> is a solution provided by Kubernetes community. It can horizontally scatter pods according to topology key. The scheduler will select the node that matches the conditions according to the configuration if users defined this rule.</p><p>Since Pod Topology Spread is evenly dispersed, it <strong>cannot</strong> support exact customized partition number and proportion configuration. Furthermore, the distribution of pods will be destroyed when scaling down.
Using WorkloadSpread can avoid these problems.</p><h3>「2」UnitedDeploymen</h3><p><a href="https://openkruise.io/docs/user-manuals/uniteddeployment">UnitedDeployment</a> is a solution provided by the OpenKruise community. It can manage pods in multiple regions by creating and managing multiple workloads.</p><p>UnitedDeployment supports the requirements of fragmentation and flexibility very well. But, it is a new workload, and the use cost and migration costs will be relatively high, whereas WorkloadSpread is a lightweight solution, which only needs to apply a simple configuration to associate the workload.</p><hr/><h2>Use Case</h2><p>In the section, I will list some application scenarios of WorkloadSpread and give corresponding configurations to help users quickly understand the WorkloadSpread feature.</p><h3>「1」Deploy 100 pods to normal node pool, rest pods to elastic node pool</h3><p><img src="../static/img/blog/2021-09-22-workloadspread/case-1.jpg" alt="case-1"/></p><pre><code class="language-yaml">subsets:
- name: subset-normal
  maxReplicas: 100
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: app.deploy/zone
      operator: In
      values:
      - normal
- name: subset-elastic 
# maxReplicas==nil means no limit for replicas
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: app.deploy/zone
      operator: In
      values:
      - elastic
</code></pre><p>When the workload has less than 100 replicas, all pods will be deployed to the normal node pool, and more than 100 are deployed to the elastic node pool. When scaling down, the pods on the elastic node will be deleted first.</p><p>Since workload spread limits the distribution of workload, but does not invade workload. Users can also dynamically adjust the number of replicas according to the resource load in combination with HPA. </p><p>In this way, it will be automatically scheduled to the elastic node pool when receiving peak flow, and give priority to releasing the resources in the elastic resource pool when the peak gone.</p><h3>「1」Deploy pods to normal node pool first, to elastic resource pool when normal node pool is insufficient</h3><p><img src="../static/img/blog/2021-09-22-workloadspread/case-2.jpg" alt="case-2"/></p><pre><code class="language-yaml">scheduleStrategy:
  type: Adaptive
  adaptive:
    rescheduleCriticalSeconds: 30
    disableSimulationSchedule: false
subsets:
- name: subset-normal
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: app.deploy/zone
      operator: In
      values:
      - normal
- name: subset-elastic
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: app.deploy/zone
      operator: In
      values:
      - elastic
</code></pre><p>Both subsets have no limit on the number of replicas, and the <code>Adaptive</code> rescheduling policy are enabled.
The goal is to preferentially deploy to the normal node pool. When normal resources are insufficient, webhook will select elastic nodes through simulated scheduling. When the pod in the normal node pool is in the pending state and exceeds the 30s threshold, the WorkloadSpread controller will delete the pod to trigger pod reconstruction, and the new pod will be scheduled to the elastic node pool. During volume reduction, the pod on the elastic node is also preferentially reduced to save costs for users.</p><h3>「3」Scatter to 3 zones, the scale is 1:1:3</h3><p><img src="../static/img/blog/2021-09-22-workloadspread/case-3.jpg" alt="case-3"/></p><pre><code class="language-yaml">subsets:
- name: subset-a
  maxReplicas: 20%
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: topology.kubernetes.io/zone
      operator: In
      values:
      - zone-a
- name: subset-b
  maxReplicas: 20%
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: topology.kubernetes.io/zone
      operator: In
      values:
      - zone-b
- name: subset-c
  maxReplicas: 60%
  requiredNodeSelectorTerm:
    matchExpressions:
    - key: topology.kubernetes.io/zone
      operator: In
      values:
      - zone-c   
</code></pre><p>WorkloadSpread ensures that the pods are scheduled according to the defined proportion when scaling up and down.</p><h3>「4」Configures different resource quotas on different CPU architecture</h3><p><img src="../static/img/blog/2021-09-22-workloadspread/case-4.jpg" alt="case-4"/></p><pre><code class="language-yaml">subsets:
- name: subset-x86-arch
  # maxReplicas...
  # requiredNodeSelectorTerm...
  patch:
    metadata:
      labels:
        resource.cpu/arch: x86
    spec: 
      containers:
      - name: main
        resources:
          limits:
            cpu: &quot;500m&quot;
            memory: &quot;800Mi&quot;
- name: subset-arm-arch
  # maxReplicas...
  # requiredNodeSelectorTerm...
  patch:
    metadata:
      labels:
        resource.cpu/arch: arm
    spec: 
      containers:
      - name: main
        resources:
          limits:
            cpu: &quot;300m&quot;
            memory: &quot;600Mi&quot;
</code></pre><p>From the above example, we have patched different labels and container <code>resources</code> for the pods of two subsets, which is convenient for us to manage the pod more finely. When workload pods are distributed on nodes of different CPU architectures, configure different resource quotas to make better use of hardware resources.</p><hr/><h2>Implementation</h2><p>WorkloadSpread is a pure bypass elastic/topology control solution. Users only need to create a corresponding WorkloadSpread config for their Deployment/Cloneset/Job/ReplicaSet Workloads. There is no need to change the them, and users will be no additional cost to use the WorkloadSpread.</p><p><img src="../static/img/blog/2021-09-22-workloadspread/arch.jpg" alt="arch"/></p><h3>「1」 How to decide the priority when scaling up?</h3><p>Multiple subsets are defined in WorkloadSpread, and each subset represents a logical domain. Users can freely define subsets according to node configuration, hardware type, zone, etc. In particular, we defined the priority of subsets:</p><ul><li><p>The priority is defined from high to low in the order from front to back, for example <code>subset[i]</code> has higher priority than <code>subset[j]</code> if <code>i &lt; j</code>.</p></li><li><p>The pods will be scheduled to the subsets with higher priority first.</p></li></ul><h3>「2」 How to decide the priority when scaling down?</h3><p>Theoretically, the bypass solution of WorkloadSpread cannot interfere with the scaling logic in the workload controller.</p><p>However, this problem has been solved in the near future. Through the unremitting efforts (feedback) of users, k8s since version 1.21, it has been supported for ReplicaSet (deployment) to specify the &quot;deletion cost&quot; of the pods by setting the annotation <code>controller.kubernetes.io/pod-deletion-cost</code>: the higher the deletion cost, the lower the priority of deletion.</p><p>Since version v0.9.0 OpenKruise, the deletion cost feature has been supported in cloneset.</p><p><strong>Therefore, the WorkloadSpread controller controls the scaling down order of the pods by adjusting their deletion cost.</strong></p><p>For example, an WorkloadSpread associated a CloneSet with 10 replicas is as follows:</p><pre><code class="language-yaml">  subsets:
  - name: subset-a
    maxReplicas: 8
  - name: subset-b
</code></pre><p>Then the deletion cost value and deletion order are as follows:</p><ul><li>8 pods in subset-a will have 200 deletion cost;</li><li>2 pods in subset-b will have 100 deletion cost, and will be deleted first;</li></ul><p>If user modify WorkloadSpread as:</p><pre><code class="language-yaml">  subsets:
  - name: subset-a
    maxReplicas: 5 # 8-&gt;5, 
  - name: subset-b
</code></pre><p>Then the deletion cost value and deletion order will also changed as follows:</p><ul><li>5 pods in subset-a will have 200 deletion cost;</li><li>3 pods in subset-a will have -100 deletion cost, and will be deleted first;</li><li>2 pods in subset-b will have 100 deletion cost;</li></ul><p>In this way, workload can preferentially scale down those pods that exceed the subset <code>maxReplicas</code> limit.</p><h3>「3」 How to solve the counting problems?</h3><p>How to ensure that webhook injects pod rules in strict accordance with the priority order of subset and the number of maxReplicas is a key problem at the implementation of WorkloadSpread.</p><h4>3.1 solving concurrency consistency problem</h4><p>Sine there may be several kruise-controller-manager pods and lots of webhook Goroutines to process the same WorkloadSpread, the concurrency consistency problem must exist.</p><p>In the status of WorkloadSpread, there are the <code>subsetStatuses</code> field corresponding to each subset. The <code>missingReplicas</code> field in it indicates the number of pods required by the subset, and - 1 indicates that there is no quantity limit (<code>subset.maxReplicas == nil</code>).</p><pre><code class="language-yaml">spec:
  subsets:
  - name: subset-a
    maxReplicas: 1
  - name: subset-b
  # ...
status:
  subsetStatuses:
  - name: subset-a
    missingReplicas: 1
  - name: subset-b
    missingReplicas: -1
  # ...
</code></pre><p>When webhook receives a pod create request:</p><ol><li>Find a suitable subset with <code>missingReplicas</code> greater than <code>0</code> or equals to <code>-1</code>  according to the subset order.</li><li>After finding a suitable subset, if <code>missingReplicas</code> is greater than <code>0</code>, subtract <code>1</code> first and try to update the WorkloadSpread status.</li><li>If the update is successful, inject the rules defined by the subset into the pod.</li><li>If the update fails, get the WorkloadSpread again to get the latest status, and return to step 1 (there is a certain limit on the number of retries).</li></ol><p>Similarly, when webhook receives a pod delete or eviction request, <code>MisingReplicas</code> will add <code>1</code> to missingreplicas and update it.</p><p>There is no doubt that we are using optimistic locks to solve update conflicts. <strong>However, it is not appropriate to only use optimistic locks</strong>, because workload will create a large number of pods in parallel, and APIServer will send many pod create requests to webhook in an instant, resulting in a lot of conflicts in parallel processing.
As we all know, optimistic lock is not suitable for too many conflicts, because the retry cost of solving conflicts is very high. To this end, we also added a WorkloadSpread level mutex to limit parallel processing to serial processing. There is a new problem in adding mutex locks, that is, after the current root obtains the lock, it is very likely that the WorkloadSpread obtained from infomer is not up-to-date, and will conflict as well. Therefore, after updating the WorkloadSpread, the Goroutine caches the latest WorkloadSpread and then releases the lock, so that the new Goroutine can directly get the latest WorkloadSpread from the cache after obtaining the lock. Of course, in the case of multiple webhooks, we still need to combine the optimistic lock mechanism to solve the conflict.</p><h4>3.2 solving data consistency problem</h4><p>So, is the <code>missingReplicas</code> field controlled by the webhook? The answer is <strong>NO</strong>, because:</p><ol><li><p>The pod create request received by webhook may not really succeed in the end (for example, pod is illegal or fails in subsequent quota verification).</p></li><li><p>The pod delete/eviction request received by webhook may not really succeed in the end (for example, it is intercepted by PDB, PUB, etc.).</p></li><li><p>There are always various possibilities in k8s, leading to the end or disappearance of the pods without going through webhook (for example, phase enters succeeded/failed, or ETCD data is lost, etc.).</p></li><li><p>At the same time, this is not in line with the end state oriented design concept.</p></li></ol><p>Therefore, the WorkloadSpread status is controlled by webhook in collaboration with the controller:</p><ul><li><p>Webhook requests link interception in pod create/delete/ eviction, and modifies the <code>missingReplicas</code>.</p></li><li><p>At the same time, the controller&#x27;s reconcile will also get all pods under the current workload, classify them according to the subset, and update <code>missingReplicas</code> to the actual missing quantity.</p></li><li><p>From the above analysis, it is likely that there is a delay for the controller to obtain the pod from the informer, so we also added the <code>creatingPods</code> map in the status. When the pod is injected at webhook, the key will be recorded as pod name and value are timestamp to the map, and the controller maintains the real <code>missingReplicas</code> in combination with the map. Similarly, there is also a <code>deleteingPods</code> map to record the delete/eviction event of the pod.</p></li></ul><h3>「4」How to do if pod schedule failed?</h3><p>The configuration of reschedule strategy is supported in WorkloadSpread. By default, the type is fixed, that is, the pod is scheduled to the corresponding subset according to the sequence of each subset and the <code>maxReplicas</code> limit.</p><p>However, in real scenarios, many times, the resources of subset may not fully meet the number of maxReplicas due to some reasons, such as insufficient resources. Users need a more flexible reschedule strategy.</p><p>The adaptive capabilities provided by WorkloadSpread are logically divided into two types:</p><ol><li><p>SimulationSchedule: scheduling records exists in informer, so we want to simulate the scheduling of pods in webhook. That is, simple filtering is performed through <code>nodeSelector</code>/<code>Affinity</code>, Tolerances, and basic resources resources. (not applicable to virtual-kubelet)</p></li><li><p>Reschedule: After scheduling the pod to a subset, if the scheduling failure exceeds the rescheduleCriticalSeconds time, mark the subset as unscheduled temporarily, and delete the pod to trigger reconstruction. By default, unscheduled will be reserved for 5min, that is, pod creation within 5min will skip this subset.</p></li></ol><hr/><h2>Conclusion</h2><p>WorkloadSpread combines some existing features of Kubernetes to give workload the ability of elastic and multi-domain deployment in the form of bypass. We hope that users can reduce workload deployment complexity by using WorkloadSpread and effectively reduce costs by taking advantage of its elastic scalability.</p><p>At present, WorkloadSpread is applied to some project in Alibaba, and adjustments in the use will be fed back to the community in time. In the future, there are some new capability plans for WorkloadSpread, such as managing the existing pods, supporting batch workloads, and even using label to match the pod across different workloads. Some of these capabilities need to actually consider the needs and scenarios of community users. I hope you can participate in kruise community, mention Issues and PRs, help users solve the problems of more cloud native deployment, and build a better community.</p><hr/><h2>Reference</h2><ul><li>WorkloadSpread: <a href="https://openkruise.io/docs/user-manuals/workloadspread">https://openkruise.io/docs/user-manuals/workloadspread</a></li><li>Pod Topology Spread Constrains: <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/</a></li><li>UnitedDeployment: <a href="https://openkruise.io/docs/user-manuals/uniteddeployment">https://openkruise.io/docs/user-manuals/uniteddeployment</a></li></ul>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenKruise 0.10.0, New features of multi-domain management, application protection]]></title>
            <link>https://openkruise.io/blog/openkruise-0.10.0</link>
            <guid>openkruise-0.10.0</guid>
            <pubDate>Mon, 06 Sep 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[On Sep 6th, 2021, OpenKruise released the latest version v0.10.0, with new features, such as WorkloadSpread and PodUnavailableBudget. This article provides an overview of this new version.]]></description>
            <content:encoded><![CDATA[<p>On Sep 6th, 2021, OpenKruise released the latest version v0.10.0, with new features, such as WorkloadSpread and PodUnavailableBudget. This article provides an overview of this new version.</p><h2>WorkloadSpread</h2><p>WorkloadSpread can distribute Pods of workload to different types of Node according to some polices, which empowers single workload the abilities for
multi-domain deployment and elastic deployment.</p><p>Some common policies include:</p><ul><li>fault toleration spread (for example, spread evenly among hosts, az, etc)</li><li>spread according to the specified ratio (for example, deploy Pod to several specified az according to the proportion)</li><li>subset management with priority, such as<ul><li>deploy Pods to ecs first, and then deploy to eci when its resources are insufficient.</li><li>deploy a fixed number of Pods to ecs first, and the rest Pods are deployed to eci.</li></ul></li><li>subset management with customization, such as<ul><li>control how many pods in a workload are deployed in different cpu arch</li><li>enable pods in different cpu arch to have different resource requirements</li></ul></li></ul><p>The feature of WorkloadSpread is similar with UnitedDeployment in OpenKruise community. Each WorkloadSpread defines multi-domain
called <code>subset</code>. Each domain may provide the limit to run the replicas number of pods called <code>maxReplicas</code>.
WorkloadSpread injects the domain configuration into the Pod by Webhook, and it also controls the order of scale in and scale out.</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: WorkloadSpread
metadata:
  name: workloadspread-demo
spec:
  targetRef:
    apiVersion: apps/v1 | apps.kruise.io/v1alpha1
    kind: Deployment | CloneSet
    name: workload-xxx
  subsets:
  - name: subset-a
    requiredNodeSelectorTerm:
      matchExpressions:
      - key: topology.kubernetes.io/zone
        operator: In
        values:
        - zone-a
    maxReplicas: 10 | 30%
  - name: subset-b
    requiredNodeSelectorTerm:
      matchExpressions:
      - key: topology.kubernetes.io/zone
        operator: In
        values:
        - zone-b
</code></pre><p>The WorkloadSpread is related to a Workload via <code>targetRef</code>. When a Pod is created by the Workload, it will be injected topology policies by Kruise according to the rules in WorkloadSpread.</p><p>Note that WorkloadSpread uses <a href="https://kubernetes.io/docs/reference/labels-annotations-taints/#pod-deletion-cost">Pod Deletion Cost</a> to control the priority of scale down. So:</p><ul><li>If the Workload type is CloneSet, it already supports the feature.</li><li>If the Workload type is Deployment or ReplicaSet, it requires your Kubernetes version &gt;= 1.22.</li></ul><p>Also you have to enable <code>WorkloadSpread</code> feature-gate when you install or upgrade Kruise.</p><h2>PodUnavailableBudget</h2><p>Kubernetes offers <a href="https://kubernetes.io/docs/tasks/run-application/configure-pdb/">Pod Disruption Budget</a> to help you run highly available applications even when you introduce frequent <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">voluntary disruptions</a>.
PDB limits the number of Pods of a replicated application that are down simultaneously from voluntary disruptions. However, it can only constrain the voluntary disruption triggered by the <a href="https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/#eviction-api">Eviction API</a>.
For example, when you run kubectl drain, the tool tries to evict all of the Pods on the Node you&#x27;re taking out of service.</p><p>In the following voluntary disruption scenarios, there are still business disruption or SLA degradation situations:</p><ol><li>The application owner update deployment&#x27;s pod template for general upgrading, while cluster administrator drain nodes to scale the cluster down(learn about <a href="https://github.com/kubernetes/autoscaler/#readme">Cluster Autoscaling</a>).</li><li>The middleware team is using SidecarSet to rolling upgrade the sidecar containers of the cluster, e.g. ServiceMesh envoy, while HPA triggers the scale-down of business applications.</li><li>The application owner and middleware team release the same Pods at the same time based on OpenKruise cloneSet, sidecarSet in-place upgrades</li></ol><p>In voluntary disruption scenarios, PodUnavailableBudget can achieve the effect of preventing application disruption or SLA degradation, which greatly improves the high availability of application services.</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: PodUnavailableBudget
metadata:
  name: web-server-pub
  namespace: web
spec:
  targetRef:
    apiVersion: apps/v1 | apps.kruise.io/v1alpha1
    kind: Deployment | CloneSet | StatefulSet | ...
    name: web-server
  # selector label query over pods managed by the budget
  # selector and TargetReference are mutually exclusive, targetRef is priority to take effect.
  # selector is commonly used in scenarios where applications are deployed using multiple workloads,
  # and targetRef is used for protection against a single workload.
# selector:
#   matchLabels:
#     app: web-server
  # maximum number of Pods unavailable for the current cloneset, the example is cloneset.replicas(5) * 60% = 3
  # maxUnavailable and minAvailable are mutually exclusive, maxUnavailable is priority to take effect
  maxUnavailable: 60%
  # Minimum number of Pods available for the current cloneset, the example is cloneset.replicas(5) * 40% = 2
# minAvailable: 40%
</code></pre><p>You have to enable the feature-gates when install or upgrade Kruise:</p><ul><li>PodUnavailableBudgetDeleteGate: protect Pod deletion or eviction.</li><li>PodUnavailableBudgetUpdateGate: protect Pod update operations, such as in-place update.</li></ul><h2>CloneSet supports scaledown priority by Spread Constraints</h2><p>When <code>replicas</code> of a CloneSet decreased, it has the arithmetic to choose Pods and delete them.</p><ol><li>Node unassigned &lt; assigned</li><li>PodPending &lt; PodUnknown &lt; PodRunning</li><li>Not ready &lt; ready</li><li><strong>Lower pod-deletion cost &lt; higher pod-deletion-cost</strong></li><li><strong>Higher spread rank &lt; lower spread rank</strong></li><li>Been ready for empty time &lt; less time &lt; more time</li><li>Pods with containers with higher restart counts &lt; lower restart counts</li><li>Empty creation time pods &lt; newer pods &lt; older pods</li></ol><p>&quot;4&quot; has provided in Kruise v0.9.0 and it is also used by WorkloadSpread to control the Pod deletion. <strong>&quot;5&quot; is added in Kruise v0.10.0 to sort Pods by their Topology Spread Constraints during scaledown.</strong></p><h2>Advanced StatefulSet supports scaleup with rate limit</h2><p>To avoid a large amount of failed Pods after user created an incorrect Advanced StatefulSet, Kruise add a <code>maxUnavailable</code> field into its <code>scaleStrategy</code>.</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1beta1
kind: StatefulSet
spec:
  # ...
  replicas: 100
  scaleStrategy:
    maxUnavailable: 10% # percentage or absolute number
</code></pre><p>When the field is set, Advanced StatefulSet will guarantee that the number of unavailable Pods should not bigger than the strategy number during Pod creation.</p><p>Note that the feature can only be used in StatefulSet with <code>podManagementPolicy=Parallel</code>.</p><h2>More</h2><p>For more changes, please refer to the <a href="https://github.com/openkruise/kruise/releases">release page</a> or <a href="https://github.com/openkruise/kruise/blob/master/CHANGELOG.md">ChangeLog</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenKruise 0.9.0, Supports Pod Restart and Deletion Protection]]></title>
            <link>https://openkruise.io/blog/openkruise-0.9.0</link>
            <guid>openkruise-0.9.0</guid>
            <pubDate>Thu, 20 May 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[On May 20, 2021, OpenKruise released the latest version v0.9.0, with new features, such as Pod restart and resource cascading deletion protection. This article provides an overview of this new version.]]></description>
            <content:encoded><![CDATA[<p>On May 20, 2021, OpenKruise released the latest version v0.9.0, with new features, such as Pod restart and resource cascading deletion protection. This article provides an overview of this new version.</p><h2>Pod Restart and Recreation</h2><p>Restarting container is a necessity in daily operation and a common technical method for recovery. In the native Kubernetes, the container granularity is inoperable. Pod, as the minimum operation unit, can only be created or deleted.</p><p>Some may ask: <em>why do users still need to pay attention to the operation such as container restart in the cloud-native era? Aren&#x27;t the services the only thing for users to focus on in the ideal Serverless model?</em></p><p>To answer this question, we need to see the differences between cloud-native architecture and traditional infrastructures. In the era of traditional physical and virtual machines, multiple application instances are deployed and run on one machine, but the lifecycles of the machine and applications are separated. Thus, application instance restart may only require a <code>systemctl</code> or <code>supervisor</code> command but not the restart of the entire machine. However, in the era of containers and cloud-native, the lifecycle of the application is bound to that of the Pod container. In other words, under normal circumstances, one container only runs one application process, and one Pod provides services for only one application instance.</p><p>Due to these restrictions, current native Kubernetes provides no API for the container (application) restart for upper-layer services. OpenKruise v0.9.0 supports restarting containers in a single Pod, compatible with standard Kubernetes clusters of version 1.16 or later. After installing or upgrading OpenKruise, users only need to create a <code>ContainerRecreateRequest</code> (CRR) object to initiate a restart process. The simplest YAML file is listed below:</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: ContainerRecreateRequest
metadata:
  namespace: pod-namespace
  name: xxx
spec:
  podName: pod-name
  containers:
  - name: app
  - name: sidecar
</code></pre><p>The value of namespace must be the same as the namespace of the Pod to be operated. The name can be set as needed. The <code>podName</code> in the spec clause indicates the Pod name. The containers indicate a list that specifies one or more container names in the Pod to restart.</p><p>In addition to the required fields above, CRR also provides a variety of optional restart policies:</p><pre><code class="language-yaml">spec:
  # ...
  strategy:
    failurePolicy: Fail
    orderedRecreate: false
    terminationGracePeriodSeconds: 30
    unreadyGracePeriodSeconds: 3
    minStartedSeconds: 10
  activeDeadlineSeconds: 300
  ttlSecondsAfterFinished: 1800
</code></pre><ul><li><code>failurePolicy</code>: Values: Fail or Ignore. Default value: Fail. If any container stops or fails to recreate, CRR ends immediately.</li><li><code>orderedRecreate</code>: Default value: false. Value true indicates when the list contains multiple containers, the new container will only be recreated after the previous recreation is finished.</li><li><code>terminationGracePeriodSeconds</code>: The time for the container to gracefully exit. If this parameter is not specified, the time defined for the Pod is used.</li><li><code>unreadyGracePeriodSeconds</code>: Set the Pod to the unready state before recreation and wait for the time expiration to execute recreation.<ul><li><code>Note</code>: This feature needs the feature-gate <code>KruisePodReadinessGate</code> to be enabled, which will inject a readinessGate when a Pod is created. Otherwise, only the pods created by the OpenKruise workload are injected with readinessGate by default. It means only these Pods can use the <code>unreadyGracePeriodSeconds</code> parameter during the CRR recreation.</li></ul></li><li><code>minStartedSeconds</code>: The minimal period that the new container remains running to judge whether the container is recreated successfully.</li><li><code>activeDeadlineSeconds</code>: The expiration period set for CRR execution to mark as ended (unfinished container will be marked as failed.)</li><li><code>ttlSecondsAfterFinished</code>: The period after which the CRR will be deleted automatically after the execution ends.</li></ul><p><strong>How it works under the hood:</strong> After it is created, a CRR is processed by the kruise-manager. Then, it will be sent to the kruise-daemon (contained by the node where Pod resides) for execution. The execution process is listed below:</p><ol><li>If <code>preStop</code> is specified for a Pod, the kruise-daemon will first call the CRI to run the command specified by <code>preStop</code> in the container.</li><li>If no <code>preStop</code> exists or <code>preStop</code> execution is completed, the kruise-daemon will call the CRI to stop the container.</li><li>When the kubelet detects the container exiting, it creates a new container with an increasing &quot;serial number&quot; and starts it. <code>postStart</code> will be executed at the same time.</li><li>When the kruise-daemon detects the start of the new container, it reports to CRR that the restart is completed.</li></ol><p><img src="/img/docs/user-manuals/containerrecreaterequest.png" alt="ContainerRecreateRequest"/></p><p>The container &quot;serial number&quot; corresponds to the <code>restartCount</code> reported by kubelet in the Pod status. Therefore, the <code>restartCount</code> of the Pod increases after the container is restarted. Temporary files written to the <code>rootfs</code> in the old container will be lost due to the container recreation, but data in the volume mount remains.</p><h2>Cascading Deletion Protection</h2><p>The level triggered automation of Kubernetes is a double-edged sword. It brings declarative deployment capabilities to applications while potentially enlarging the influence of mistakes at a final-state scale. For example, with the cascading deletion mechanism, once an owning resource is deleted under normal circumstances (non-orphan deletion), all owned resources associated will be deleted by the following rules:</p><ol><li>If a CRD is deleted, all its corresponding CR will be cleared.</li><li>If a namespace is deleted, all resources in this namespace, including Pods, will be cleared.</li><li>If a workload (Deployment, StatefulSet, etc) is deleted, all Pods under it will be cleared.</li></ol><p>Due to failures caused by cascading deletion, we have heard many complaints from Kubernetes users and developers in the community. It is unbearable for any enterprise to mistakenly delete objects at such a large scale in the production environment.</p><p>Therefore, in OpenKruise v0.9.0, we applied the feature of cascading deletion protection to community in the hope of ensuring stability for more users. If you want to use this feature in the current version, the feature-gate of <code>ResourcesDeletionProtection</code> needs to be explicitly enabled when installing or upgrading OpenKruise.</p><p>A label of <code>policy.kruise.io/delete-protection</code> can be given on the resource objects that require protection. Its value can be the following two things:</p><ul><li><strong>Always</strong>: The object cannot be deleted unless the label is removed.</li><li><strong>Cascading</strong>: The object cannot be deleted if any subordinate resources are available.</li></ul><p>The following table lists the supported resource types and cascading relationships:</p><table><thead><tr><th>Kind</th><th>Group</th><th>Version</th><th><strong>Cascading</strong> judgement</th></tr></thead><tbody><tr><td><code>Namespace</code></td><td>core</td><td>v1</td><td>whether there is active Pods in this namespace</td></tr><tr><td><code>CustomResourceDefinition</code></td><td>apiextensions.k8s.io</td><td>v1beta1, v1</td><td>whether there is existing CRs of this CRD</td></tr><tr><td><code>Deployment</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>StatefulSet</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>ReplicaSet</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>CloneSet</code></td><td>apps.kruise.io</td><td>v1alpha1</td><td>whether the replicas is 0</td></tr><tr><td><code>StatefulSet</code></td><td>apps.kruise.io</td><td>v1alpha1, v1beta1</td><td>whether the replicas is 0</td></tr><tr><td><code>UnitedDeployment</code></td><td>apps.kruise.io</td><td>v1alpha1</td><td>whether the replicas is 0</td></tr></tbody></table><h2>New Features of CloneSet</h2><h3>Deletion Priority</h3><p>The <code>controller.kubernetes.io/pod-deletion-cost</code> annotation was added to Kubernetes after version 1.21. <code>ReplicaSet</code> will sort the Kubernetes resources according to this cost value during scale in. CloneSet has supported the same feature since OpenKruise v0.9.0.</p><p>Users can configure this annotation in the pod. The int type of its value indicates the deletion cost of a certain pod compared to other pods under the same CloneSet. Pods with a lower cost have a higher deletion priority. If this annotation is not set, the deletion cost of the pod is 0 by default.</p><p><em>Note</em>: This deletion order is not determined solely by deletion cost. The real order serves like this:</p><ol><li>Not scheduled &lt; scheduled</li><li>PodPending &lt; PodUnknown &lt; PodRunning</li><li>Not ready &lt; ready</li><li><strong>Smaller pod-deletion cost &lt; larger pod-deletion cost</strong></li><li>Period in the Ready state: short &lt; long</li><li>Containers restart: more times &lt; fewer times</li><li>Creation time: short &lt; long</li></ol><h3>Image Pre-Download for In-Place Update</h3><p>When CloneSet is used for the in-place update of an application, only the container image is updated, while the Pod is not rebuilt. This ensures that the node where the Pod is located will not change. Therefore, if the CloneSet pulls the new image from all the Pod nodes in advance, the Pod in-place update speed will be improved substantially in subsequent batch releases.</p><p>If you want to use this feature in the current version, the feature-gate of <code>PreDownloadImageForInPlaceUpdate</code> needs to be explicitly enabled when installing or upgrading OpenKruise. If you update the images in the CloneSet template and the publish policy supports in-place update, CloneSet will create an <code>ImagePullJob</code> object automatically (the batch image pre-download function provided by OpenKruise) to download new images in advance on the node where the Pod is located.</p><p>By default, CloneSet sets the parallelism to 1 for <code>ImagePullJob</code>, which means images are pulled for one node and then another. For any adjustment, you can set the parallelism in the CloneSet annotation by executing the following code:</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: CloneSet
metadata:
  annotations:
    apps.kruise.io/image-predownload-parallelism: &quot;5&quot;
</code></pre><h3>Pod Replacement by Scale Out and Scale In</h3><p>In previous versions, the <code>maxUnavailable</code> and <code>maxSurge</code> policies of CloneSet only take effect during the application release process. In OpenKruise v0.9.0 and later versions, these two policies also function when deleting a specified Pod.</p><p>When the user specifies one or more Pods to be deleted through <code>podsToDelete</code> or <code>apps.kruise.io/specified-delete</code>: true, CloneSet will only execute deletion when the number of unavailable Pods (of the total replicas) is less than the value of <code>maxUnavailable</code>. In addition, if the user has configured the <code>maxSurge</code> policy, the CloneSet will possibly create a new Pod first, wait for the new Pod to be ready, and then delete the old specified Pod.</p><p>The replacement method depends on the value of maxUnavailable and the number of unavailable Pods. For example:</p><ul><li>For a CloneSet, <code>maxUnavailable=2, maxSurge=1</code> and only <code>pod-a</code> is unavailable. If you specify <code>pod-b</code> to be deleted, CloneSet will delete it promptly and create a new Pod.</li><li>For a CloneSet, <code>maxUnavailable=1, maxSurge=1</code> and only <code>pod-a</code> is unavailable. If you specify <code>pod-b</code> to be deleted, CloneSet will create a new Pod, wait for it to be ready, and then delete the pod-b.</li><li>For a CloneSet, <code>maxUnavailable=1, maxSurge=1</code> and only <code>pod-a</code> is unavailable. If you specify this <code>pod-a</code> to be deleted, CloneSet will delete it promptly and create a new Pod.</li></ul><h3>Efficient Rollback Based on Partition Final State</h3><p>In the native workload, Deployment does not support phased release, while StatefulSet provides partition semantics to allow users to control the times of gray scale upgrades. OpenKruise workloads, such as CloneSet and Advanced StatefulSet, also provide partitions to support phased release.</p><p>For CloneSet, the semantics of Partition is <strong>the number or percentage of Pods remaining in the old version</strong>. For example, for a CloneSet with 100 replicas, if the partition value is changed in the sequence of 80 :arrow_right: 60 :arrow_right: 40 :arrow_right: 20 :arrow_right: 0 by steps during the image upgrade, the CloneSet is released in five batches.</p><p>However, in the past, whether it is Deployment, StatefulSet, or CloneSet, if rollback is required during the release process, the template information (image) must be changed back to the old version. During the phased release of StatefulSet and CloneSet, reducing partition value will trigger the upgrade to a new version. Increasing partition value will not trigger rollback to the old version.</p><p>The partition of CloneSet supports the &quot;final state rollback&quot; function after v0.9.0. If the feature-gate <code>CloneSetPartitionRollback</code> is enabled when installing or upgrading OpenKruise, increasing the partition value will trigger CloneSet to roll back the corresponding number of new Pods to the old version.</p><p>There is a clear advantage here. During the phased release, only the partition value needs to be adjusted to flexibly control the numbers of old and new versions. However, the &quot;old and new versions&quot; for CloneSet correspond to <code>updateRevision</code> and <code>currentRevision</code> in its status:</p><ul><li>updateRevision: The version of the template defined by the current CloneSet.</li><li>currentRevision: The template version of CloneSet during the <strong>previous successful full release</strong>.</li></ul><h3>Short Hash</h3><p>By default, the value of <code>controller-revision-hash</code> in Pod label set by CloneSet is the full name of the <code>ControllerRevision</code>. For example:</p><pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    controller-revision-hash: demo-cloneset-956df7994
</code></pre><p>The name is concatenated with the CloneSet name and the <code>ControllerRevision</code> hash value. Generally, the hash value is 8 to 10 characters in length. In Kubernetes, a label cannot exceed 63 characters in length. Therefore, the name of CloneSet cannot exceed 52 characters in length, or the Pod cannot be created.</p><p>In v0.9.0, the new feature-gate <code>CloneSetShortHash</code> is introduced. If it is enabled, CloneSet will set the value of <code>controller-revision-hash</code> in the Pod to a hash value only, like 956df7994. Therefore, the length restriction of the CloneSet name is eliminated. (CloneSet can still recognize and manage the Pod with revision labels in the full format, even if this function is enabled.)</p><h2>New Features of SidecarSet</h2><h3>Sidecar Hot Upgrade Function</h3><p>SidecarSet is a workload provided by OpenKruise to manage sidecar containers separately. Users can inject and upgrade specified sidecar containers within a certain range of Pods using <code>SidecarSet</code>.</p><p>By default, for the independent in-place sidecar upgrade, the sidecar stops the container of the old version first and then creates a container of the new version. This method applies to sidecar containers that do not affect the Pod service availability, such as the log collection agent. However, for sidecar containers acting as a proxy such as Istio Envoy, this upgrade method is defective. Envoy, as a proxy container in the Pod, handles all the traffic. If users restart and upgrade directly, service availability will be affected. Thus, you need a complex grace termination and coordination mechanism to upgrade the envoy sidecar separately. Therefore, we offer a new solution for the upgrade of this kind of sidecar containers, namely, hot upgrade:</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: SidecarSet
spec:
  # ...
  containers:
  - name: nginx-sidecar
    image: nginx:1.18
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - /usr/local/bin/nginx-agent migrate
    upgradeStrategy:
      upgradeType: HotUpgrade
      hotUpgradeEmptyImage: empty:1.0.0
</code></pre><ul><li><code>upgradeType</code>: <code>HotUpgrade</code> indicates that the type of the sidecar container is a hot upgrade, so the hot upgrade solution, <code>hotUpgradeEmptyImage</code>, will be executed. When performing a hot upgrade on the sidecar container, an empty container is required to switch services during the upgrade. The empty container has almost the same configuration as the sidecar container, except the image address, for example, command, lifecycle, and probe, but it does no actual work.</li><li><code>lifecycle.postStart</code>: State migration. This procedure completes the state migration during the hot upgrade. The script needs to be executed according to business characteristics. For example, NGINX hot upgrade requires shared Listen FD and traffic reloading.</li></ul><h2>More</h2><p>For more changes, please refer to the <a href="https://github.com/openkruise/kruise/releases">release page</a> or <a href="https://github.com/openkruise/kruise/blob/master/CHANGELOG.md">ChangeLog</a>.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[UnitedDeploymemt - Supporting Multi-domain Workload Management]]></title>
            <link>https://openkruise.io/blog/uniteddeployment</link>
            <guid>uniteddeployment</guid>
            <pubDate>Wed, 20 Nov 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Ironically, probably every cloud user knew (or should realized that) failures in Cloud resources]]></description>
            <content:encoded><![CDATA[<p>Ironically, probably every cloud user knew (or should realized that) failures in Cloud resources
are inevitable. Hence, high availability is probably one of the most desirable features that
Cloud Provider offers for cloud users. For example, in AWS, each geographic region has
multiple isolated locations known as Availability Zones (AZs).
AWS provides various AZ-aware solutions to allow the compute or storage resources of the user
applications to be distributed across multiple AZs in order to tolerate AZ failure, which indeed
happened in the past. </p><p>In Kubernetes, the concept of AZ is not realized by an API object. Instead,
an AZ is usually represented by a group of hosts that have the same location label.
Although hosts within the same AZ can be identified by labels, the capability of distributing Pods across
AZs was missing in Kubernetes default scheduler. Hence it was difficult to use single
<code>StatefulSet</code> or <code>Deployment</code> to perform  AZ-aware Pods deployment. Fortunately,
in Kubernetes 1.16, a new feature called <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">&quot;Pod Topology Spread Constraints&quot;</a>
was introduced. Users now can add new constraints in the Pod Spec, and scheduler
will enforce the constraints so that Pods can be distributed across failure
domains such as AZs, regions or nodes, in a uniform fashion.</p><p>In Kruise, <strong>UnitedDeploymemt</strong> provides an alternative to achieve high availability in
a cluster that consists of multiple fault domains - that is, managing multiple homogeneous
workloads, and each workload is dedicated to a single <code>Subset</code>. Pod distribution across AZs is
determined by the replica number of each workload.
Since each <code>Subset</code> is associated with a workload, UnitedDeployment can support
finer-grained rollout and deployment strategies.
In addition, UnitedDeploymemt can be further extended to support
multiple clusters! Let us reveal how UnitedDeployment is designed.</p><h2>Using <code>Subsets</code> to describe domain topology</h2><p>UnitedDeploymemt uses <code>Subset</code> to represent a failure domain. <code>Subset</code> API
primarily specifies the nodes that forms the domain and the number of replicas, or
the percentage of total replicas, run in this domain. UnitedDeployment manages
subset workloads against a specific domain topology, described by a <code>Subset</code> array.</p><pre><code>type Topology struct {
    // Contains the details of each subset.
    Subsets []Subset
}

type Subset struct {
    // Indicates the name of this subset, which will be used to generate
    // subset workload name prefix in the format &#x27;&lt;deployment-name&gt;-&lt;subset-name&gt;-&#x27;.
    Name string

    // Indicates the node select strategy to form the subset.
    NodeSelector corev1.NodeSelector

    // Indicates the number of the subset replicas or percentage of it on the
    // UnitedDeployment replicas.
    Replicas *intstr.IntOrString
}
</code></pre><p>The specification of the subset workload is saved in <code>Spec.Template</code>. UnitedDeployment
only supports <code>StatefulSet</code> subset workload as of now. An interesting part of <code>Subset</code>
design is that now user can specify <strong>customized Pod distribution</strong> across AZs, which is not
necessarily a uniform distribution in some cases. For example, if the AZ
utilization or capacity are not homogeneous, evenly distributing Pods may lead to Pod deployment
failure due to lack of resources. If users have prior knowledge about AZ resource capacity/usage,
UnitedDeployment can help to apply an optimal Pod distribution to ensure overall
cluster utilization remains balanced. Of course, if not specified, a uniform Pod distribution
will be applied to maximize availability.</p><h2>Customized subset rollout <code>Partitions</code></h2><p>User can update all the UnitedDeployment subset workloads by providing a
new version of subset workload template.
Note that UnitedDeployment does not control
the entire rollout process of all subset workloads, which is typically done by another rollout
controller built on top of it. Since the replica number in each <code>Subset</code> can be different,
it will be much more convenient to allow user to specify the individual rollout <code>Partition</code> of each
subset workload instead of using one <code>Partition</code> to rule all, so that they can be upgraded in the same pace.
UnitedDeployment provides <code>ManualUpdate</code> strategy to customize per subset rollout <code>Partition</code>.</p><pre><code>type UnitedDeploymentUpdateStrategy struct {
    // Type of UnitedDeployment update.
    Type UpdateStrategyType
    // Indicates the partition of each subset.
    ManualUpdate *ManualUpdate
}

type ManualUpdate struct {
    // Indicates number of subset partition.
    Partitions map[string]int32
}
</code></pre><p><img src="/img/blog/2019-11-20-uniteddeployment/uniteddeployment-1.png" alt="multi-cluster controller"/></p><p>This makes it fairly easy to coordinate multiple subsets rollout. For example,
as illustrated in Figure 1, assuming UnitedDeployment manages three subsets and
their replica numbers are 4, 2, 2 respectively, a rollout
controller can realize a canary release plan of upgrading 50% of Pods in each
subset at a time by setting subset partitions to 2, 1, 1 respectively.
The same cannot be easily achieved by using a single workload controller like <code>StatefulSet</code>
or <code>Deployment</code>.</p><h2>Multi-Cluster application management (In future)</h2><p>UnitedDeployment can be extended to support multi-cluster workload
management. The idea is that <code>Subsets</code> may not only
reside in one cluster, but also spread over multiple clusters.
More specifically, domain topology specification will associate
a <code>ClusterRegistryQuerySpec</code>, which describes the clusters that UnitedDeployment
may distribute Pods to. Each cluster is represented by a custom resource managed by a
ClusterRegistry controller using Kubernetes <a href="https://github.com/kubernetes/cluster-registry">cluster registry APIs</a>.</p><pre><code>type Topology struct {
  // ClusterRegistryQuerySpec is used to find the all the clusters that
  // the workload may be deployed to. 
  ClusterRegistry *ClusterRegistryQuerySpec
  // Contains the details of each subset including the target cluster name and
  // the node selector in target cluster.
  Subsets []Subset
}

type ClusterRegistryQuerySpec struct {
  // Namespaces that the cluster objects reside.
  // If not specified, default namespace is used.
  Namespaces []string
  // Selector is the label matcher to find all qualified clusters.
  Selector   map[string]string
  // Describe the kind and APIversion of the cluster object.
  ClusterType metav1.TypeMeta
}

type Subset struct {
  Name string

  // The name of target cluster. The controller will validate that
  // the TargetCluster exits based on Topology.ClusterRegistry.
  TargetCluster *TargetCluster

  // Indicate the node select strategy in the Subset.TargetCluster.
  // If Subset.TargetCluster is not set, node selector strategy refers to
  // current cluster.
  NodeSelector corev1.NodeSelector

  Replicas *intstr.IntOrString 
}

type TargetCluster struct {
  // Namespace of the target cluster CRD
  Namespace string
  // Target cluster name
  Name string
}
</code></pre><p>A new <code>TargetCluster</code> field is added to the <code>Subset</code> API. If it presents, the
<code>NodeSelector</code> indicates the node selection logic in the target cluster. Now
UnitedDeployment controller can distribute application Pods to multiple clusters by
instantiating a <code>StatefulSet</code> workload in each target cluster with a specific
replica number (or a percentage of total replica), as illustrated in Figure 2.</p><p><img src="/img/blog/2019-11-20-uniteddeployment/uniteddeployment-2.png" alt="multi-cluster	controller"/></p><p>At a first glance, UnitedDeployment looks more like a federation
controller following the design pattern of <a href="https://github.com/kubernetes-sigs/kubefed">Kubefed</a>,
but it isn&#x27;t. The fundamental difference is that Kubefed focuses on propagating arbitrary
object types to remote clusters instead of managing an application across clusters.
In this example, had a Kubefed style controller been used, each <code>StatefulSet</code> workload in
individual cluster would have a replica of 100. UnitedDeployment focuses more on
providing the ability of managing multiple workloads in multiple clusters on behalf
of one application, which is absent in Kubernetes community to the best of our
knowledge.</p><h2>Summary</h2><p>This blog post introduces UnitedDeployment, a new controller which helps managing
application spread over multiple domains (in arbitrary clusters).
It not only allows evenly distributing Pods over AZs,
which arguably can be more efficiently done using the new Pod Topology Spread
Constraint APIs though, but also enables flexible workload deployment/rollout and
supports multi-cluster use cases in the future.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning Concurrent Reconciling]]></title>
            <link>https://openkruise.io/blog/learning-concurrent-reconciling</link>
            <guid>learning-concurrent-reconciling</guid>
            <pubDate>Sun, 10 Nov 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[The concept of controller in Kubernete is one of the most important reasons that make it successful.]]></description>
            <content:encoded><![CDATA[<p>The concept of controller in Kubernete is one of the most important reasons that make it successful.
Controller is the core mechanism that supports Kubernetes APIs to ensure the system reaches
the desired state. By leveraging CRDs/controllers and operators, it is fairly easy for
other systems to integrate with Kubernetes. </p><p>Controller runtime library and the corresponding controller tool <a href="https://book.kubebuilder.io/introduction.html">KubeBuilder</a>
are widely used by many developers to build their customized Kubernetes controllers. In Kruise project,
we also use Kubebuilder to generate scaffolding codes that implement the &quot;reconciling&quot; logic.
In this blog post, I will share some learnings from
Kruise controller development, particularly, about concurrent reconciling. </p><p>Some people may already notice that controller runtime supports concurrent reconciling.
Check for the options (<a href="https://github.com/kubernetes-sigs/controller-runtime/blob/81842d0e78f7111f0566156189806e2801e3adf1/pkg/controller/controller.go#L32">source</a>)
used to create new controller:  </p><pre><code>type Options struct {
    // MaxConcurrentReconciles is the maximum number of concurrent Reconciles which can be run. Defaults to 1.
    MaxConcurrentReconciles int

    // Reconciler reconciles an object
    Reconciler reconcile.Reconciler
}
</code></pre><p>Concurrent reconciling is quite useful when the states of the controller&#x27;s watched objects change so
frequently that a large amount of reconcile requests are sent to and queued in the reconcile queue.
Multiple reconcile loops do help drain the reconcile queue much more quickly compared to the default single
reconcile loop case. Although this is a great feature for performance, without digging into the code,
an immediate concern that a developer may raise is that will this introduce consistency issue?
i.e., is it possible that two reconcile loops handle the same object at the same time?</p><p>The answer is NO, as you may expect. The &quot;magic&quot; is enforced by the workqueue
implementation in Kubernetes <code>client-go</code>, which is used by controller runtime reconcile queue.
The workqueue algorithm (<a href="https://github.com/kubernetes/client-go/blob/a57d0056dbf1d48baaf3cee876c123bea745591f/util/workqueue/queue.go#L65">source</a>)
is demonstrated in Figure 1.</p><p><img src="/img/blog/2019-11-10-learning-concurrent-reconciling/workqueue.png" alt="workqueue"/></p><p>Basically, the workqueue uses a <code>queue</code> and two <code>sets</code> to coordinate the process of handling multiple reconciling
requests against the same object. Figure 1(a) presents the initial state of handling four reconcile requests,
two of which target the same object A. When a request arrives, the target object is first added to the <code>dirty set</code>
or dropped if it presents in <code>dirty set</code>,  and then pushed to the <code>queue</code> only if it is not presented in
<code>processing set</code>. Figure 1(b) shows the case of adding three requests consecutively.
When a reconciling loop is ready to serve a request, it gets the target object from the <code>front</code> of the queue. The
object is also added to the <code>processing set</code> and removed from the <code>dirty set</code> (Figure 1(c)).
Now if a request of the processing object arrives, the object is only added to the <code>dirty set</code>, not
to the <code>queue</code> (Figure 1(d)). This guarantees that an object is only handled by one reconciling
loop. When reconciling is done, the object is removed from the <code>processing set</code>. If the object is also
shown in the <code>dirty set</code>, it is added back to the <code>back</code> of the <code>queue</code> (Figure 1(e)).</p><p>The above algorithm has following implications:</p><ul><li>It avoids concurrent reconciling for the same object.</li><li>The object processing order can be different from arriving order even if there is only one reconciling thread.
This usually would not be a problem since the controller still reconciles to the final cluster state. However,
the out of order reconciling may cause a significant delay for a request.
<img src="/img/blog/2019-11-10-learning-concurrent-reconciling/workqueue-starve.png" alt="workqueue-starve"/>.... For example, as illustrated in
Figure 2, assuming there is only one reconciling thread and two requests targeting the same object A arrive, one of
them will be processed and object A will be added to the <code>dirty set</code> (Figure 2(b)).
If the reconciling takes a long time and during which a large number of new reconciling requests arrive,
the queue will be filled up by the new requests (Figure 2(c)). When reconciling is done, object A will be
added to the <code>back</code> of the <code>queue</code> (Figure 2(d)). It would not be handled until all the requests coming after had been
handled, which can cause a noticeable long delay. The workaround is actually simple - <strong>USE CONCURRENT RECONCILES</strong>.
Since the cost of an idle go routine is fairly small, the overhead of having multiple reconcile threads is
low even if the controller is idle. It seems that the <code>MaxConcurrentReconciles</code> value should
be overwritten to a value larger than the default 1 (CloneSet uses 10 for example).</li><li>Last but not the least, reconcile requests can be dropped (if the target exists in <code>dirty set</code>). This means
that we cannot assume that the controller can track all the object state change events. Recalling a presentation
given by <a href="https://speakerdeck.com/thockin/edge-vs-level-triggered-logic">Tim Hockin</a>, Kubernetes controller
is level triggered, not edge triggered. It reconciles for state, not for events. </li></ul><p>Thanks for reading the post, hope it helps.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kruise Workload Classification Guidance]]></title>
            <link>https://openkruise.io/blog/workload-classification-guidance</link>
            <guid>workload-classification-guidance</guid>
            <pubDate>Thu, 10 Oct 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Kubernetes does not provide a clear guidance about which controller is the best fit for]]></description>
            <content:encoded><![CDATA[<p>Kubernetes does not provide a clear guidance about which controller is the best fit for
a user application. Sometimes, this does not seem to be a big problem if users understand
both the application and workload well. For example, users usually know when to choose
<code>Job/CronJob</code> or <code>DaemonSet</code> since the concepts of these workload are straightforward -
the former is designed for temporal batch style applications and the latter is suitable
for long running Pod which is distributed in every node. On the other hand, the usage
boundary between <code>Deployment</code> and <code>StatefulSet</code> is vague. An application managed by
a <code>Deployment</code> conceptually can be managed by a <code>StatefulSet</code> as well, the opposite may
also apply as long as the Pod <code>OrderedReady</code> capability of <code>StatefulSet</code> is not mandatory.
Furthermore, as more and more customized controllers/operators become available in Kubernetes
community, finding suitable controller can be a nonnegligible user problem especially
when some controllers have functional overlaps.</p><p>Kruise attempts to mitigate the problem from two aspects:</p><ul><li>Carefully design the new controllers in the Kruise suite to avoid unnecessary functional
duplications that may confuse users.</li><li>Establish a classification mechanism for existing workload controllers so that user
can more easily understand the use cases of them. We will elaborate this more in this
post. The first and most intuitive criterion for classification is the controller name.</li></ul><h3>Controller Name Convention</h3><p>An easily understandable controller name can certainly help adoption. After consulting
with many internal/external Kubernetes users, we decide to use the following naming
conventions in Kruise. Note that these conventions are not contradicted with the controller
names used in upstream controllers.</p><ul><li><p><strong>Set</strong> -suffix names: This type of controller manages Pods directly. Examples
include <code>CloneSet</code>, <code>ReplicaSet</code> and <code>SidecarSet</code>. It supports
various depolyment/rollout strategies in Pod level.</p></li><li><p><strong>Deployment</strong> -suffix names: This type of controller does not manage Pods
directly. Instead, it manages one or many <strong>Set</strong> -suffix workload instances which are
created on behalf of one application. The controller can provide capabilities
to orchestrate the deployment/rollout of multiple instances. For example, <code>Deployment</code>
manages <code>ReplicaSet</code> and provides rollout capability which is not available in <code>ReplicaSet</code>.
<code>UnitedDeployment</code> (planned in <a href="https://github.com/openkruise/kruise/projects">M3 release</a>)
manages multiple <code>StatefulSet</code> created in respect of multiple domains
(i.e., fault domains) within one cluster.</p></li><li><p><strong>Job</strong> -suffix names: This type of controller manages batch style applications with
different depolyment/rollout strategies. For example, <code>BroadcastJob</code> distributes a
job style Pod to every node in the cluster.</p></li></ul><p><strong>Set</strong>, <strong>Deployment</strong> and <strong>Job</strong> are widely adopted terms in Kubernetes community.
Kruise leverages them with certain extensions.</p><p>Can we further distinguish controllers with the same name suffix? Normally the string prior to
the suffix should be self-explainable, but in many cases it is hard to find a right word to
describe what the controller does. Check to see how <code>StatefulSet</code> is originated in
this <a href="https://github.com/kubernetes/kubernetes/issues/27430">thread</a>. It takes four
months for community to decide to use the name <code>StatefulSet</code> to replace the original
name <code>PetSet</code> although the new name still confuse people by looking
at its API documentation. This example showcases that sometimes a well-thought-out name
may not be helpful to identify controller. Again, Kruise does not plan to resolve
this problem. As an incremental effort, Kruise considers the following criterion to help classify
<strong>Set</strong> -suffix controllers.</p><h3>Fixed Pod Name</h3><p>One unique property of <code>StatefulSet</code> is that it maintains consistent identities for
Pod network and storage. Essentially, this is done by fixing Pod names.
Pod name can identify both network and storage since it is part of DNS record and
can be used to name Pod volume claim. Why is this property needed given that all Pods in
<code>StatefulSet</code> are created from the same Pod template?
A well known use case is to manage distributed coordination server application such as
etcd or Zookeeper. This type of application requires the cluster member
(i.e., the Pod) to access the same data (in Pod volume) whenever a member is
reconstructed upon failure, in order to function correctly. To differentiate the term
<code>State</code> in <code>StatefulSet</code> from the same term used in other computer science areas,
I&#x27;d like to associate <code>State</code> with Pod name in this document. That being said, controllers
like <code>ReplicaSet</code> and <code>DaemonSet</code> are <code>Stateless</code> since they don&#x27;t require to reuse the
old Pod name when a Pod is recreated.</p><p>Supporting <code>Stateful</code> does lead to inflexibility for controller. <code>StatefulSet</code> relies on ordinal
numbers to realize fixing Pod names. The workload rollout and scaling
has to be done in a strict order. As a consequence, some useful enhancements to <code>StatefulSet</code>
become impossible. For example,</p><ul><li>Selective Pod upgrade and Pod deletion (when scale in). These features can be helpful
when Pods are spread across different regions or fault domains.</li><li>The ability of taking control over existing Pods with arbitrary names. There are
cases where Pod creation is done by one controller but Pod lifecycle management
is done by another controller (e.g., <code>StatefulSet</code>).</li></ul><p>We found that many containerized applications do not require the <code>Stateful</code> property
of fixing Pod names, and <code>StatefulSet</code> is hard to be extended for those
applications in many cases. To fill the gap, Kruise has released a new controller
called <code>CloneSet</code> to manage the <code>Stateless</code> applications. In a nutshell, <code>CloneSet</code>
provides PVC support and enriched rollout and management capabilities.
The following table roughly compares Advanced StatefulSet and CloneSet in a few aspects.</p><table><thead><tr><th>Features</th><th align="center">Advanced StatefulSet</th><th align="center">CloneSet</th></tr></thead><tbody><tr><td>PVC</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Pod name</td><td align="center">Ordered</td><td align="center">Random</td></tr><tr><td>Inplace upgrade</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Max unavailable</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Selective deletion</td><td align="center">No</td><td align="center">Yes</td></tr><tr><td>Selective upgrade</td><td align="center">No</td><td align="center">Yes</td></tr><tr><td>Change Pod ownership</td><td align="center">No</td><td align="center">Yes</td></tr></tbody></table><p>Now, a clear recommendation to Kruise users is if your applications require fixed Pod names (identities for Pod network and storage), you can start with <code>Advanced StatefulSet</code>.
Otherwise, <code>CloneSet</code> is the primary choice of <strong>Set</strong> -suffix controllers (if <code>DaemonSet</code> is not
applicable).</p><h3>Summary</h3><p>Kruise aims to provide intuitive names for new controllers. As a supplement, this post
provides additional guidance for Kruise users to pick the right controller for their
applications. Hope it helps!</p>]]></content:encoded>
        </item>
    </channel>
</rss>