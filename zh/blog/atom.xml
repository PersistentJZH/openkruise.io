<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://openkruise.io/zh/blog</id>
    <title>OpenKruise Blog</title>
    <updated>2021-12-13T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://openkruise.io/zh/blog"/>
    <subtitle>OpenKruise Blog</subtitle>
    <icon>https://openkruise.io/zh/img/openkruise.ico</icon>
    <entry>
        <title type="html"><![CDATA[OpenKruise v1.0：云原生应用自动化达到新的高峰]]></title>
        <id>openkruise-1.0</id>
        <link href="https://openkruise.io/zh/blog/openkruise-1.0"/>
        <updated>2021-12-13T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[云原生应用自动化管理套件、CNCF Sandbox 项目 -- OpenKruise，近期发布了 v1.0 大版本。]]></summary>
        <content type="html"><![CDATA[<p>云原生应用自动化管理套件、CNCF Sandbox 项目 -- OpenKruise，近期发布了 v1.0 大版本。</p><p><a href="https://openkruise.io">OpenKruise</a> 是针对 Kubernetes 的增强能力套件，聚焦于云原生应用的部署、升级、运维、稳定性防护等领域。所有的功能都通过 CRD 等标准方式扩展，可以适用于 1.16 以上版本的任意 Kubernetes 集群。单条 helm 命令即可完成 Kruise 的一键部署，无需更多配置。</p><p><img src="/img/blog/2021-12-13-release-1.0/features-zh.png" alt="openkruise-features|center|450x400"/></p><p>总得来看，目前 OpenKruise 提供的能力分为几个领域：</p><ul><li><strong>应用工作负载</strong>：面向无状态、有状态、daemon 等多种类型应用的高级部署发布策略，例如原地升级、灰度流式发布等。</li><li><strong>Sidecar 容器管理</strong>：支持独立定义 sidecar 容器，完成动态注入、独立原地升级、热升级等功能。</li><li><strong>增强运维能力</strong>：包括容器原地重启、镜像预拉取、容器启动顺序保障等。</li><li><strong>应用分区管理</strong>：管理应用在多个分区（可用区、不同机型等）上的部署比例、顺序、优先级等。</li><li><strong>应用安全防护</strong>：帮助应用在 Kubernetes 之上获得更高的安全性保障与可用性防护。</li></ul><h2>版本解析</h2><p>在 v1.0 大版本中，OpenKruise 带来了多种新的特性，同时也对不少已有功能做了增强与优化。</p><p>首先要说的是，从 v1.0 开始 OpenKruise 将 CRD/WehhookConfiguration 等资源配置的版本从 <code>v1beta1</code> 升级到 <code>v1</code>，因此可以<strong>支持 Kubernetes v1.22 及以上版本的集群，但同时也要求 Kubernetes 的版本不能低于 v1.16</strong>。</p><p>以下对 v1.0 的部分功能做简要介绍，详细的 ChangeLog 列表请查看 OpenKruise Github 上的 release 说明以及官网文档。</p><h3>1. 支持环境变量原地升级</h3><p><em>Author: <a href="https://github.com/FillZpp">@FillZpp</a></em></p><p>OpenKruise 从早期版本开始就支持了 “原地升级” 功能，主要应用于 CloneSet 与 Advanced StatefulSet 两种工作负载上。简单来说，原地升级使得应用在升级的过程中，不需要删除、新建 Pod 对象，而是通过对 Pod 中容器配置的修改来达到升级的目的。</p><p><img src="/img/docs/core-concepts/inplace-update-comparation.png" alt="inplace-update-comparation|center|450x400"/></p><p>如上图所示，原地升级过程中只修改了 Pod 中的字段，因此：</p><ol><li>可以避免如 <em>调度</em>、<em>分配 IP</em>、<em>分配、挂载盘</em> 等额外的操作和代价。</li><li>更快的镜像拉取，因为开源复用已有旧镜像的大部分 layer 层，只需要拉取新镜像变化的一些 layer。</li><li>当一个容器在原地升级时，Pod 的网络、挂载盘、以及 Pod 中的其他容器不会受到影响，仍然维持运行。</li></ol><p>然而，OpenKruise 过去只能对 Pod 中 image 字段的更新做原地升级，对于其他字段仍然只能采用与 Deployment 相似的重建升级。一直以来，我们收到很多用户反馈，希望支持对 env 等更多字段的原地升级 -- 由于受到 kube-apiserver 的限制，这是很难做到的。</p><p>经过我们的不懈努力，OpenKruise 终于在 v1.0 版本中，支持了通过 Downward API 的方式支持了 env 环境变量的原地升级。例如对以下CloneSet YAML，用户将配置定义在 annotation 中并关联到对应 env 中。后续在修改配置时，只需要更新 annotation value 中的值，Kruise 就会对 Pod 中所有 env 里引用了这个 annotation 的容器触发原地重建，从而生效这个新的 value 配置。</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: CloneSet
metadata:
  ...
spec:
  replicas: 1
  template:
    metadata:
      annotations:
        app-config: &quot;... the real env value ...&quot;
    spec:
      containers:
      - name: app
        env:
        - name: APP_CONFIG
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations[&#x27;app-config&#x27;]
  updateStrategy:
    type: InPlaceIfPossible
</code></pre><p><em>与此同时，我们在这个版本中也去除了过去对镜像原地升级的<code>imageID</code>限制，即支持相同imageID的两个镜像替换升级。</em></p><p>具体使用方式请参考<a href="/docs/core-concepts/inplace-update">文档</a>。</p><h3>2. 配置跨命名空间分发</h3><p><em>Author: <a href="https://github.com/veophi">@veophi</a></em></p><p>在对 Secret、ConfigMap 等 namespace-scoped 资源进行跨 namespace 分发及同步的场景中，原生 kubernetes 目前只支持用户 one-by-one 地进行手动分发与同步，十分地不方便。</p><p>典型的案例有：</p><ul><li>当用户需要使用 SidecarSet 的 imagePullSecrets 能力时，要先重复地在相关 namespaces 中创建对应的 Secret，并且需要确保这些 Secret 配置的正确性和一致性。</li><li>当用户想要采用 ConfigMap 来配置一些<strong>通用</strong>的环境变量时，往往需要在多个 namespaces 做 ConfigMap 的下发，并且后续的修改往往也要求多 namespaces 之间保持同步。</li></ul><p>因此，面对这些需要跨 namespaces 进行资源分发和<strong>多次同步</strong>的场景，我们期望一种更便捷的分发和同步工具来自动化地去做这件事，为此我们设计并实现了一个新的CRD --- <strong>ResourceDistribution</strong>。</p><p>ResourceDistribution 目前支持 <strong>Secret</strong> 和 <strong>ConfigMap</strong> 两类资源的分发和同步。</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: ResourceDistribution
metadata:
  name: sample
spec:
  resource:
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: game-demo
    data:
      ...
  targets:
    namespaceLabelSelector:
      ...
    # or includedNamespaces, excludedNamespaces
</code></pre><p>如上述 YAML 所示，ResourceDistribution是一类 <strong>cluster-scoped</strong> 的 CRD，其主要由 <strong><code>resource</code></strong> 和 <strong><code>targets</code></strong> 两个字段构成，其中 <strong><code>resource</code></strong> 字段用于描述用户所要分发的资源，<strong><code>targets</code></strong> 字段用于描述用户所要分发的目标命名空间。</p><p>具体使用方式请参考<a href="/docs/user-manuals/resourcedistribution">文档</a>。</p><h3>3. 容器启动顺序控制</h3><p><em>Author: <a href="https://github.com/Concurrensee">@Concurrensee</a></em></p><p>对于 Kubernetes 的一个 Pod，其中的多个容器可能存在依赖关系，比如 容器B 中应用进程的运行依赖于 容器A 中的应用。因此，多个容器之间存在顺序关系的需求：</p><ul><li>容器A 先启动，启动成功后才可以启动 容器B</li><li>容器B 先退出，退出完成后才可以停止 容器A</li></ul><p>通常来说 Pod 容器的启动和退出顺序是由 Kubelet 管理的。Kubernetes 曾经有一个 KEP 计划在 container 中增加一个 type 字段来标识不同类型容器的启停优先级。但是由于 sig-node 考虑到对现有代码架构的改动太大，目前这个 KEP 已经被拒绝了。</p><p>因此，OpenKruise 在 v1.0 中提供了名为 <strong>Container Launch Priority</strong> 的功能，用于控制一个 Pod 中多个容器的强制启动顺序：</p><ol><li>对于任意一个 Pod 对象，只需要在 annotations 中定义 <code>apps.kruise.io/container-launch-priority: Ordered</code>，则 Kruise 会按照 Pod 中 <code>containers</code> 容器列表的顺序来保证其中容器的串行启动。</li><li>如果要自定义 <code>containers</code> 中多个容器的启动顺序，则在容器 env 中添加 <code>KRUISE_CONTAINER_PRIORITY</code> 环境变量，value 值是范围在 <code>[-2147483647, 2147483647]</code> 的整数。一个容器的 priority 值越大，会保证越先启动。</li></ol><p>具体使用方式请参考<a href="/docs/user-manuals/containerlaunchpriority">文档</a>。</p><h3>4. <code>kubectl-kruise</code> 命令行工具</h3><p><em>Author: <a href="https://github.com/hantmac">@hantmac</a></em></p><p>过去 OpenKruise 是通过 kruise-api、client-java 等仓库提供了 Go、Java 等语言的 Kruise API 定义以及客户端封装，可供用户在自己的应用程序中引入使用。但仍然有不少用户在测试环境下需要灵活地用命令行操作 workload 资源。</p><p>然而原生 <code>kubectl</code> 工具提供的 <code>rollout</code>、<code>set image</code> 等命令只能适用于原生的 workload 类型，如 Deployment、StatefulSet，并不能识别 OpenKruise 中扩展的 workload 类型。</p><p>因此，OpenKruise 最新提供了 <code>kubectl-kruise</code> 命令行工具，它是 <code>kubectl</code> 的标准插件，提供了许多适用于 OpenKruise workload 的功能。</p><pre><code class="language-bash"># rollout undo cloneset
$ kubectl kruise rollout undo cloneset/nginx

#  rollout status advanced statefulset
$ kubectl kruise rollout status statefulsets.apps.kruise.io/sts-demo

# set image of a cloneset
$ kubectl kruise set image cloneset/nginx busybox=busybox nginx=nginx:1.9.1
</code></pre><p>具体使用方式请参考<a href="/docs/cli-tool/kubectl-plugin">文档</a>。</p><h3>5. 其余部分功能改进与优化</h3><p><strong>CloneSet:</strong></p><ul><li>通过 <code>scaleStrategy.maxUnavailable</code> 策略支持流式扩容</li><li>Stable revision 判断逻辑变化，当所有 Pod 版本与 updateRevision 一致时则标记为 currentRevision</li></ul><p><strong>WorkloadSpread:</strong></p><ul><li>支持接管存量 Pod 到匹配的 subset 分组中</li><li>优化 webhook 在 Pod 注入时的更新与重试逻辑</li></ul><p><strong>Advanced DaemonSet:</strong></p><ul><li>支持对 Daemon Pod 做原地升级</li><li>引入 progressive annotation 来选择是否按 partition 限制 Pod 创建</li></ul><p><strong>SidecarSet:</strong></p><ul><li>解决 SidecarSet 过滤屏蔽 inactive Pod</li><li>在 <code>transferenv</code> 中新增 <code>SourceContainerNameFrom</code> 和 <code>EnvNames</code> 字段，来解决 container name 不一致与大量 env 情况下的冗余问题</li></ul><p><strong>PodUnavailableBudget:</strong></p><ul><li>新增 “跳过保护” 标识</li><li>PodUnavailableBudget controller 关注 workload 工作负载的 replicas 变化</li></ul><p><strong>NodeImage:</strong></p><ul><li>加入 <code>--nodeimage-creation-delay</code> 参数，并默认等待新增 Node ready 一段时间后同步创建 NodeImage</li></ul><p><strong>UnitedDeployment:</strong></p><ul><li>解决 <code>NodeSelectorTerms</code> 为 nil 情况下 Pod <code>NodeSelectorTerms</code> 长度为 0 的问题</li></ul><p><strong>Other optimization:</strong></p><ul><li>kruise-daemon 采用 protobuf 协议操作 Pod 资源</li><li>暴露 cache resync 为命令行参数，并在 chart 中设置默认值为 0</li><li>解决 certs 更新时的 http checker 刷新问题</li><li>去除对 forked controller-tools 的依赖，改为使用原生 controller-tools 配合 markers 注解</li></ul>]]></content>
        <author>
            <name>Siyu Wang</name>
            <uri>https://github.com/FillZpp</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[OpenKruise 0.10.0：新增应用弹性拓扑管理、应用防护等能力]]></title>
        <id>openkruise-0.10.0</id>
        <link href="https://openkruise.io/zh/blog/openkruise-0.10.0"/>
        <updated>2021-09-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[本文将带你一览 v0.10.0 的新变化，其中新增的 WorkloadSpread、PodUnavailableBudget 等大颗粒特性后续还将有专文详细介绍其设计实现原理。]]></summary>
        <content type="html"><![CDATA[<p>本文将带你一览 v0.10.0 的新变化，其中新增的 WorkloadSpread、PodUnavailableBudget 等大颗粒特性后续还将有专文详细介绍其设计实现原理。</p><h2>WorkloadSpread：旁路的应用弹性拓扑管理能力</h2><p>在应用部署运维的场景下，有着多种多样的拓扑打散以及弹性的诉求。其中最常见、最基本的，就是按某种或几种拓扑水平打散，比如：</p><ul><li>应用部署需要按 node 维度打散，避免堆叠（提高容灾能力）</li><li>应用部署需要按 AZ（available zone）维度打散（提高容灾能力）</li></ul><p>这些基本的诉求，通过 Kubernetes 原生提供的 pod affinity、<a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">topology spread constraints</a> 等能力目前都能够满足了。但在实际的生产场景下，还有着太多更加复杂的分区与弹性需求，以下举一些实际的例子：</p><ul><li>按 zone 打散时，需要指定在不同 zone 中部署的比例数，比如某个应用在 zone a、b、c 中部署的 Pod 数量比例为 1 : 1 : 2 等（由于一些现实的原因比如该应用在多个 zone 中的流量不均衡等）</li><li>存在多个 zone 或不同机型的拓扑，应用扩容时，优先部署到某个 zone 或机型上，当资源不足时再部署到另一个 zone 或机型上（往后以此类推）；应用缩容时，要按反向顺序，优先缩容后面 zone 或机型上的 Pod（往前以此类推）</li><li>存在多个基础的节点池和弹性的节点池，应用部署时需要固定数量或比例的 Pod 部署在基础节点池，其余的都扩到弹性节点池</li></ul><p>对于这些例子，过去一般只能将一个应用拆分为多个 Workload（比如 Deployment）来部署，才能解决应用在不同拓扑下采用不同比例数量、扩缩容优先级、资源感知、弹性选择等场景的基本问题，但还是需要 PaaS 层深度定制化，来支持对一个应用多个 Workload 的精细化管理。</p><p>针对这些问题，在 Kruise v0.10.0 版本中新增了 WorkloadSpread 资源，目前它支持配合 Deployment、ReplicaSet、CloneSet 这些 Workload 类型，来管理它们下属 Pod 的分区与弹性拓扑。
以下是一个简化的例子：</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: WorkloadSpread
metadata:
  name: workloadspread-demo
spec:
  targetRef:
    apiVersion: apps/v1 | apps.kruise.io/v1alpha1
    kind: Deployment | CloneSet
    name: workload-xxx
  subsets:
  - name: subset-a
    requiredNodeSelectorTerm:
      matchExpressions:
      - key: topology.kubernetes.io/zone
        operator: In
        values:
        - zone-a
    maxReplicas: 10 | 30%
  - name: subset-b
    requiredNodeSelectorTerm:
      matchExpressions:
      - key: topology.kubernetes.io/zone
        operator: In
        values:
        - zone-b
</code></pre><p>创建这个 WorkloadSpread 可以通过 targetRef 关联到一个 Workload 对象上，然后这个 Workload 在扩容 pod 的过程中，Pod 会被 Kruise 按上述策略注入对应的拓扑规则。这是一种旁路的注入和管理方式，本身不会干涉 Workload 对 Pod 的扩缩容、发布管理。</p><p>注意：WorkloadSpread 对 Pod 的缩容的优先级控制是通过 <a href="https://kubernetes.io/docs/reference/labels-annotations-taints/#pod-deletion-cost">Pod Deletion Cost</a> 来实现的：</p><ul><li>如果 Workload 类型是 CloneSet，则已经支持了这个 feature，可以实现缩容优先级</li><li>如果 Workload 类型是 Deployment/ReplicaSet，则要求 Kubernetes version &gt;= 1.21，且在 1.21 中要在 kube-controller-manager 上开启 <code>PodDeletionCost</code> 这个 feature-gate</li></ul><p>使用 WorkloadSpread 功能，需要在 安装/升级 Kruise v0.10.0 的时候打开 WorkloadSpread 这个 feature-gate。</p><h2>PodUnavailableBudget：应用可用性防护</h2><p>在诸多 <a href="https://kubernetes.io/docs/concepts/workloads/pods/disruptions/">Voluntary Disruption</a> 场景中 Kubernetes 原生提供的 <a href="https://kubernetes.io/docs/tasks/run-application/configure-pdb/">Pod Disruption Budget（PDB）</a> 通过限制同时中断的 Pod 数量，来保证应用的高可用性。</p><p>但还有很多场景中，即便有 PDB 防护依然将会导致业务中断、服务降级，比如：</p><ul><li>应用 owner 通过 Deployment 正在进行版本升级，与此同时集群管理员由于机器资源利用率过低正在进行 node 缩容</li><li>中间件团队利用 SidecarSet 正在原地升级集群中的sidecar版本（例如：ServiceMesh envoy），同时HPA正在对同一批应用进行缩容</li><li>应用 owner 和中间件团队利用 CloneSet、SidecarSet 原地升级的能力，正在对同一批 Pod 进行升级</li></ul><p>这其实很好理解 -- PDB 只能防控通过 Eviction API 来触发的 Pod 驱逐（例如 kubectl drain驱逐node上面的所有Pod），但是对于 Pod 删除、原地升级 等很多操作是无法防护的。</p><p>在 Kruise v0.10.0 版本中新增的 PodUnavailableBudget（PUB）功能，则是对原生 PDB 的强化扩展。它包含了 PDB 自身的能力，并在此基础上增加了对更多 Voluntary Disruption 操作的防护，包括但不限于 Pod 删除、原地升级 等。</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: PodUnavailableBudget
metadata:
  name: web-server-pub
  namespace: web
spec:
  targetRef:
    apiVersion: apps/v1 | apps.kruise.io/v1alpha1
    kind: Deployment | CloneSet | StatefulSet | ...
    name: web-server
  # selector 与 targetRef 二选一配置
# selector:
#   matchLabels:
#     app: web-server
  # 保证的最大不可用数量
  maxUnavailable: 60%
  # 保证的最小可用数量
# minAvailable: 40%
</code></pre><p>使用 PodUnavailableBudget 功能，需要在 安装/升级 Kruise v0.10.0 的时候打开feature-gate（两个可以选择打开一个，也可以都打开）：</p><ul><li>PodUnavailableBudgetDeleteGate：拦截防护 Pod 删除、驱逐 等操作</li><li>PodUnavailableBudgetUpdateGate：拦截防护 Pod 原地升级 等更新操作</li></ul><h2>CloneSet 支持按拓扑规则缩容</h2><p>在 CloneSet 缩容（调小 replicas 数量）的时候，选择哪些 Pod 删除是有一套固定算法排序的：</p><ol><li>未调度 &lt; 已调度</li><li>PodPending &lt; PodUnknown &lt; PodRunning</li><li>Not ready &lt; ready</li><li><strong>较小 pod-deletion cost &lt; 较大 pod-deletion cost</strong></li><li><strong>较大打散权重 &lt; 较小</strong></li><li>处于 Ready 时间较短 &lt; 较长</li><li>容器重启次数较多 &lt; 较少</li><li>创建时间较短 &lt; 较长</li></ol><p>其中，“4” 是在 Kruise v0.9.0 中开始提供的特性，用于支持用户指定删除顺序（WorkloadSpread 就是利用这个功能实现缩容优先级）；<strong>而 “5” 则是当前 v0.10.0 提供的特性，即在缩容的时候会参考应用的拓扑打散来排序</strong>。</p><ul><li>如果应用配置了 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">topology spread constraints</a>，则 CloneSet 缩容时会按照其中的 topology 维度打散来选择 Pod 删除（比如尽量打平多个 zone 上部署 Pod 的数量）</li><li>如果应用没有配置 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">topology spread constraints</a>，则默认情况下 CloneSet 缩容时会按照 node 节点维度打散来选择 Pod 删除（尽量减少同 node 上的堆叠数量）</li></ul><h2>Advanced StatefulSet 支持流式扩容</h2><p>为了避免在一个新 Advanced StatefulSet 创建后有大量失败的 pod 被创建出来，从 Kruise v0.10.0 版本开始引入了在 scale strategy 中的 maxUnavailable 策略：</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1beta1
kind: StatefulSet
spec:
  # ...
  replicas: 100
  scaleStrategy:
    maxUnavailable: 10% # percentage or absolute number
</code></pre><p>当这个字段被设置之后，Advanced StatefulSet 会保证创建 pod 之后不可用 pod 数量不超过这个限制值。
比如说，上面这个 StatefulSet 一开始只会一次性创建 10 个 pod。在此之后，每当一个 pod 变为 running、ready 状态后，才会再创建一个新 pod 出来。</p><p>注意：这个功能只允许在 podManagementPolicy 是 <code>Parallel</code> 的 StatefulSet 中使用。</p><h2>More</h2><p>更多版本变化，请参考 <a href="https://github.com/openkruise/kruise/releases">release page</a> 或 <a href="https://github.com/openkruise/kruise/blob/master/CHANGELOG.md">ChangeLog</a></p>]]></content>
        <author>
            <name>Siyu Wang</name>
            <uri>https://github.com/FillZpp</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[OpenKruise 0.9.0：新增Pod容器重启、资源删除防护等功能]]></title>
        <id>openkruise-0.9.0</id>
        <link href="https://openkruise.io/zh/blog/openkruise-0.9.0"/>
        <updated>2021-05-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[OpenKruise 在 2021.5.20 发布了最新的 v0.9.0 版本，新增了 Pod 容器重启、资源级联删除防护等重磅功能，本文以下对新版本做整体的概览介绍。]]></summary>
        <content type="html"><![CDATA[<p>OpenKruise 在 2021.5.20 发布了最新的 v0.9.0 版本，新增了 Pod 容器重启、资源级联删除防护等重磅功能，本文以下对新版本做整体的概览介绍。</p><h2>Pod 容器重启/重建</h2><p>“重启” 是一个很朴素的需求，即使日常运维的诉求，也是技术领域较为常见的 “恢复手段”。而在原生的 Kubernetes 中，并没有提供任何对容器粒度的操作能力，Pod 作为最小操作单元也只有创建、删除两种操作方式。</p><p>有的同学可能会问，在云原生时代，为什么用户还要关注容器重启这种运维操作呢？在理想的 serverless 模式下，业务只需要关心服务自身就好吧？</p><p>这来自于云原生架构和过去传统基础基础设施的差异性。在传统的物理机、虚拟机时代，一台机器上往往会部署和运行多个应用的实例，并且机器和应用的生命周期是不同的；在这种情况下，应用实例的重启可能仅仅是一条 systemctl 或 supervisor 之类的指令，而无需将整个机器重启。然而，在容器与云原生模式下，应用的生命周期是和 Pod 容器绑定的；即常规情况下，一个容器只运行一个应用进程，一个 Pod 也只提供一个应用实例的服务。</p><p>基于上述的限制，目前原生 Kubernetes 之下是没有 API 来为上层业务提供容器（应用）重启能力的。而 Kruise v0.9.0 版本提供了一种单 Pod 维度的容器重启能力，兼容 1.16 及以上版本的标准 Kubernetes 集群。在安装或升级 Kruise 之后，只需要创建 ContainerRecreateRequest（简称 CRR） 对象来指定重启，最简单的 YAML 如下：</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: ContainerRecreateRequest
metadata:
  namespace: pod-namespace
  name: xxx
spec:
  podName: pod-name
  containers:
  - name: app
  - name: sidecar
</code></pre><p>其中，namespace 需要与要操作的 Pod 在同一个命名空间，name 可自选。spec 中 podName 是 Pod 名字，containers 列表则可以指定 Pod 中一个或多个容器名来执行重启。</p><p>除了上述必选字段外，CRR 还提供了多种可选的重启策略：</p><pre><code class="language-yaml">spec:
  # ...
  strategy:
    failurePolicy: Fail
    orderedRecreate: false
    terminationGracePeriodSeconds: 30
    unreadyGracePeriodSeconds: 3
    minStartedSeconds: 10
  activeDeadlineSeconds: 300
  ttlSecondsAfterFinished: 1800
</code></pre><ul><li><code>failurePolicy</code>: Fail 或 Ignore，默认 Fail；表示一旦有某个容器停止或重建失败，CRR 立即结束</li><li><code>orderedRecreate</code>: 默认 false；true 表示列表有多个容器时，等前一个容器重建完成了，再开始重建下一个</li><li><code>terminationGracePeriodSeconds</code>: 等待容器优雅退出的时间，不填默认用 Pod 中定义的时间</li><li><code>unreadyGracePeriodSeconds</code>: 在重建之前先把 Pod 设为 not ready，并等待这段时间后再开始执行重建<ul><li>注：该功能依赖于 KruisePodReadinessGate 这个 feature-gate 要打开，后者会在每个 Pod 创建的时候注入一个 readinessGate。 否则，默认只会给 Kruise workload 创建的 Pod 注入 readinessGate，也就是说只有这些 Pod 才能在 CRR 重建时使用 unreadyGracePeriodSeconds</li></ul></li><li><code>minStartedSeconds</code>: 重建后新容器至少保持运行这段时间，才认为该容器重建成功</li><li><code>activeDeadlineSeconds</code>: 如果 CRR 执行超过这个时间，则直接标记为结束（未完成的容器标记为失败）</li><li><code>ttlSecondsAfterFinished</code>: CRR 结束后，过了这段时间自动被删除掉</li></ul><p>实现原理：当用户创建了 CRR 后，经过了 kruise-manager 中心端的初步处理，会被 Pod 所在节点上的 kruise-daemon 收到并开始执行。执行的过程如下：</p><ol><li>如果 Pod 容器定义了 preStop，kruise-daemon 会先走 CRI 运行时 exec 到容器中执行 preStop</li><li>如果没有 preStop 或执行完成，kruise-daemon 调用 CRI 接口将容器停止</li><li>kubelet 感知到容器退出，则会新建一个 “序号” 递增的新容器，并开始启动（以及执行 postStart）</li><li>kruise-daemon 感知到新容器启动成功，上报 CRR 重启完成</li></ol><p><img src="/img/docs/user-manuals/containerrecreaterequest.png" alt="ContainerRecreateRequest"/></p><p>上述的容器 “序号” 其实就对应了 Pod status 中 kubelet 上报的 restartCount。因此，在容器重启后会看到 Pod 的 restartCount 增加。另外，因为容器发生了重建，之前临时写到旧容器 rootfs 中的文件会丢失，但是 volume mount 挂载卷中的数据仍然存在。</p><h2>级联删除防护</h2><p>Kubernetes 的面向终态自动化是一把 “双刃剑”，它既为应用带来了声明式的部署能力，同时也潜在地会将一些误操作行为被终态化放大。例如它的 “级联删除” 机制，即正常情况（非 orphan 删除）下一旦父类资源被删除，则所有子类资源都会被关联删除：</p><ol><li>删除一个 CRD，其所有对应的 CR 都被清理掉</li><li>删除一个 namespace，这个命名空间下包括 Pod 在内所有资源都被一起删除</li><li>删除一个 workload（Deployment/StatefulSet/...），则下属所有 Pod 被删除</li></ol><p>类似这种 “级联删除” 带来的故障，我们已经听到不少社区 K8s 用户和开发者带来的抱怨。对于任何一家企业来说，其生产环境发生这种规模误删除都是不可承受之痛。</p><p>因此，在 Kruise v0.9.0 版本中，我们建立了防级联删除能力，期望能为更多的用户带来稳定性保障。在当前版本中如果需要使用该功能，则在安装或升级 Kruise 的时候需要显式打开 <code>ResourcesDeletionProtection</code> 这个 feature-gate。</p><p>对于需要防护删除的资源对象，用户可以给其打上 policy.kruise.io/delete-protection 标签，value 可以有两种：</p><ul><li>Always: 表示这个对象禁止被删除，除非上述 label 被去掉</li><li>Cascading：这个对象如果还有可用的下属资源，则禁止被删除</li></ul><p>目前支持的资源类型、以及 cascading 级联关系如下：</p><table><thead><tr><th>Kind</th><th>Group</th><th>Version</th><th><strong>Cascading</strong> judgement</th></tr></thead><tbody><tr><td><code>Namespace</code></td><td>core</td><td>v1</td><td>whether there is active Pods in this namespace</td></tr><tr><td><code>CustomResourceDefinition</code></td><td>apiextensions.k8s.io</td><td>v1beta1, v1</td><td>whether there is existing CRs of this CRD</td></tr><tr><td><code>Deployment</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>StatefulSet</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>ReplicaSet</code></td><td>apps</td><td>v1</td><td>whether the replicas is 0</td></tr><tr><td><code>CloneSet</code></td><td>apps.kruise.io</td><td>v1alpha1</td><td>whether the replicas is 0</td></tr><tr><td><code>StatefulSet</code></td><td>apps.kruise.io</td><td>v1alpha1, v1beta1</td><td>whether the replicas is 0</td></tr><tr><td><code>UnitedDeployment</code></td><td>apps.kruise.io</td><td>v1alpha1</td><td>whether the replicas is 0</td></tr></tbody></table><h2>CloneSet 新增功能</h2><h3>删除优先级</h3><p><code>controller.kubernetes.io/pod-deletion-cost</code> 是从 Kubernetes 1.21 版本后加入的 annotation，ReplicaSet 在缩容时会参考这个 cost 数值来排序。 CloneSet 从 Kruise v0.9.0 版本后也同样支持了这个功能。</p><p>用户可以把这个 annotation 配置到 pod 上，它的 value 数值是 int 类型，表示这个 pod 相较于同个 CloneSet 下其他 pod 的 &quot;删除代价&quot;，代价越小的 pod 删除优先级相对越高。 没有设置这个 annotation 的 pod 默认 deletion cost 是 0。</p><p>注意这个删除顺序并不是强制保证的，因为真实的 pod 的删除类似于下述顺序：</p><ol><li>未调度 &lt; 已调度</li><li>PodPending &lt; PodUnknown &lt; PodRunning</li><li>Not ready &lt; ready</li><li><strong>较小 pod-deletion cost &lt; 较大 pod-deletion cost</strong></li><li>处于 Ready 时间较短 &lt; 较长</li><li>容器重启次数较多 &lt; 较少</li><li>创建时间较短 &lt; 较长</li></ol><h3>配合原地升级的镜像预热</h3><p>当使用 CloneSet 做应用原地升级时，只会升级容器镜像、而 Pod 不会发生重建。这就保证了 Pod 升级前后所在 node 不会发生变化，从而在原地升级的过程中，如果 CloneSet 提前在所有 Pod 节点上先把新版本镜像拉取好，则在后续的发布批次中 Pod 原地升级速度会得到大幅度提高。</p><p>在当前版本中如果需要使用该功能，则在安装或升级 Kruise 的时候需要显式打开 <code>PreDownloadImageForInPlaceUpdate</code> 这个 feature-gate。打开后，当用户更新了 CloneSet template 中的镜像、且发布策略支持原地升级，则 CloneSet 会自动为这个新镜像创建 ImagePullJob 对象（OpenKruise 提供的批量镜像预热功能），来提前在 Pod 所在节点上预热新镜像。</p><p>默认情况下 CloneSet 给 ImagePullJob 配置的并发度是 1，也就是一个个节点拉镜像。 如果需要调整，你可以在 CloneSet annotation 上设置其镜像预热时的并发度：</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: CloneSet
metadata:
  annotations:
    apps.kruise.io/image-predownload-parallelism: &quot;5&quot;
</code></pre><h3>先扩再缩的 Pod 置换方式</h3><p>在过去版本中，CloneSet 的 <code>maxUnavailable</code>、<code>maxSurge</code> 策略只对应用发布过程生效。而从 Kruise v0.9.0 版本开始，这两个策略同样会对 Pod 指定删除生效。</p><p>也就是说，当用户通过 <code>podsToDelete</code> 或 <code>apps.kruise.io/specified-delete: true</code> 方式（具体见官网文档）来指定一个或多个 Pod 期望删除时，CloneSet 只会在当前不可用 Pod 数量（相对于 replicas 总数）小于 maxUnavailable 的时候才执行删除。同时，如果用户配置了 maxSurge 策略，则 CloneSet 有可能会先创建一个新 Pod、等待新 Pod ready、再删除指定的旧 Pod。</p><p>具体采用什么样的置换方式，取决于当时的 maxUnavailable 和实际不可用 Pod 数量。比如：</p><ul><li>对于一个 CloneSet <code>maxUnavailable=2, maxSurge=1</code> 且有一个 <code>pod-a</code> 处于不可用状态， 如果你对另一个 <code>pod-b</code> 指定删除， 那么 CloneSet 会立即删除它，然后创建一个新 Pod。</li><li>对于一个 CloneSet <code>maxUnavailable=1, maxSurge=1</code> 且有一个 <code>pod-a</code> 处于不可用状态， 如果你对另一个 <code>pod-b</code> 指定删除， 那么 CloneSet 会先新建一个 Pod、等待它 ready，最后再删除 pod-b。</li><li>对于一个 CloneSet <code>maxUnavailable=1, maxSurge=1</code> 且有一个 <code>pod-a</code> 处于不可用状态， 如果你对这个 <code>pod-a</code> 指定删除， 那么 CloneSet 会立即删除它，然后创建一个新 Pod。</li><li>...</li></ul><h3>基于 partition 终态的高效回滚</h3><p>在原生的 workload 中，Deployment 自身发布不支持灰度发布，StatefulSet 有 partition 语义来允许用户控制灰度升级的数量；而 Kruise workload 如 CloneSet、Advanced StatefulSet，也都提供了 partition 来支持灰度分批。</p><p>对于 CloneSet，Partition 的语义是 <strong>保留旧版本 Pod 的数量或百分比</strong>。比如说一个 100 个副本的 CloneSet，在升级镜像时将 partition 数值阶段性改为 80 -&gt; 60 -&gt; 40 -&gt; 20 -&gt; 0，则完成了分 5 批次发布。</p><p>但过去，不管是 Deployment、StatefulSet 还是 CloneSet，在发布的过程中如果想要回滚，都必须将 template 信息（镜像）重新改回老版本。后两者在灰度的过程中，将 partition 调小会触发旧版本升级为新版本，但再次 partition 调大则不会处理。</p><p>从 v0.9.0 版本开始，CloneSet 的 partition 支持了 “终态回滚” 功能。如果在安装或升级 Kruise 的时候打开了 <code>CloneSetPartitionRollback</code> 这个 feature-gate，则当用户将 partition 调大时，CloneSet 会将对应数量的新版本 Pod 重新回滚到老版本。</p><p>这样带来的好处是显而易见的：在灰度发布的过程中，只需要前后调节 partition 数值，就能灵活得控制新旧版本的比例数量。但需要注意的是，CloneSet 所依据的 “新旧版本” 对应的是其 status 中的 updateRevision 和 currentRevision：</p><ul><li>updateRevision：对应当前 CloneSet 所定义的 template 版本</li><li>currentRevision：该 CloneSet 前一次全量发布成功的 template 版本</li></ul><h3>短 hash</h3><p>默认情况下，CloneSet 在 Pod label 中设置的 <code>controller-revision-hash</code> 值为 <code>ControllerRevision</code> 的完整名字，比如：</p><pre><code class="language-yaml">apiVersion: v1
kind: Pod
metadata:
  labels:
    controller-revision-hash: demo-cloneset-956df7994
</code></pre><p>它是通过 CloneSet 名字和 ControllerRevision hash 值拼接而成。 通常 hash 值长度为 8~10 个字符，而 Kubernetes 中的 label 值不能超过 63 个字符。 因此 CloneSet 的名字一般是不能超过 52 个字符的，如果超过了，则无法成功创建出 Pod。</p><p>在 v0.9.0 版本引入了 <code>CloneSetShortHash</code> 新的 feature-gate。 如果它被打开，CloneSet 只会将 Pod 中的 <code>controller-revision-hash</code> 的值只设置为 hash 值，比如 956df7994，因此 CloneSet 名字的长度不会有任何限制了。（即使启用该功能，CloneSet 仍然会识别和管理过去存量的 revision label 为完整格式的 Pod。）</p><h2>SidecarSet 新增功能</h2><h3>Sidecar 热升级</h3><p>SidecarSet 是 Kruise 提供的独立管理 sidecar 容器的 workload。用户可以通过 SidecarSet，来在一定范围的 Pod 中注入和升级指定的 sidecar 容器。</p><p>默认情况下，sidecar 的独立原地升级是先停止旧版本的容器，然后创建新版本的容器。这种方式更加适合不影响Pod服务可用性的sidecar容器，比如说日志收集 agent，但是对于很多代理或运行时的 sidecar 容器，例如 Istio Envoy，这种升级方法就有问题了。Envoy 作为 Pod 中的一个代理容器，代理了所有的流量，如果直接重启升级，Pod 服务的可用性会受到影响。如果需要单独升级 envoy sidecar，就需要复杂的 grace 终止和协调机制。所以我们为这种 sidecar 容器的升级提供了一种新的解决方案，即热升级（hot upgrade）。</p><pre><code class="language-yaml">apiVersion: apps.kruise.io/v1alpha1
kind: SidecarSet
spec:
  # ...
  containers:
  - name: nginx-sidecar
    image: nginx:1.18
    lifecycle:
      postStart:
        exec:
          command:
          - /bin/bash
          - -c
          - /usr/local/bin/nginx-agent migrate
    upgradeStrategy:
      upgradeType: HotUpgrade
      hotUpgradeEmptyImage: empty:1.0.0
</code></pre><ul><li><code>upgradeType</code>: HotUpgrade代表该sidecar容器的类型是hot upgrade，将执行热升级方案hotUpgradeEmptyImage: 当热升级sidecar容器时，业务必须要提供一个empty容器用于热升级过程中的容器切换。empty容器同sidecar容器具有相同的配置（除了镜像地址），例如：command, lifecycle, probe等，但是它不做任何工作。</li><li><code>lifecycle.postStart</code>: 状态迁移，该过程完成热升级过程中的状态迁移，该脚本需要由业务根据自身的特点自行实现，例如：nginx热升级需要完成Listen FD共享以及流量排水（reload）</li></ul><h2>更多</h2><p>更多版本变化，请参考 <a href="https://github.com/openkruise/kruise/releases">release page</a> 或 <a href="https://github.com/openkruise/kruise/blob/master/CHANGELOG.md">ChangeLog</a></p>]]></content>
        <author>
            <name>Siyu Wang</name>
            <uri>https://github.com/FillZpp</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UnitedDeploymemt - Supporting Multi-domain Workload Management]]></title>
        <id>uniteddeployment</id>
        <link href="https://openkruise.io/zh/blog/uniteddeployment"/>
        <updated>2019-11-20T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Ironically, probably every cloud user knew (or should realized that) failures in Cloud resources]]></summary>
        <content type="html"><![CDATA[<p>Ironically, probably every cloud user knew (or should realized that) failures in Cloud resources
are inevitable. Hence, high availability is probably one of the most desirable features that
Cloud Provider offers for cloud users. For example, in AWS, each geographic region has
multiple isolated locations known as Availability Zones (AZs).
AWS provides various AZ-aware solutions to allow the compute or storage resources of the user
applications to be distributed across multiple AZs in order to tolerate AZ failure, which indeed
happened in the past. </p><p>In Kubernetes, the concept of AZ is not realized by an API object. Instead,
an AZ is usually represented by a group of hosts that have the same location label.
Although hosts within the same AZ can be identified by labels, the capability of distributing Pods across
AZs was missing in Kubernetes default scheduler. Hence it was difficult to use single
<code>StatefulSet</code> or <code>Deployment</code> to perform  AZ-aware Pods deployment. Fortunately,
in Kubernetes 1.16, a new feature called <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/">&quot;Pod Topology Spread Constraints&quot;</a>
was introduced. Users now can add new constraints in the Pod Spec, and scheduler
will enforce the constraints so that Pods can be distributed across failure
domains such as AZs, regions or nodes, in a uniform fashion.</p><p>In Kruise, <strong>UnitedDeploymemt</strong> provides an alternative to achieve high availability in
a cluster that consists of multiple fault domains - that is, managing multiple homogeneous
workloads, and each workload is dedicated to a single <code>Subset</code>. Pod distribution across AZs is
determined by the replica number of each workload.
Since each <code>Subset</code> is associated with a workload, UnitedDeployment can support
finer-grained rollout and deployment strategies.
In addition, UnitedDeploymemt can be further extended to support
multiple clusters! Let us reveal how UnitedDeployment is designed.</p><h2>Using <code>Subsets</code> to describe domain topology</h2><p>UnitedDeploymemt uses <code>Subset</code> to represent a failure domain. <code>Subset</code> API
primarily specifies the nodes that forms the domain and the number of replicas, or
the percentage of total replicas, run in this domain. UnitedDeployment manages
subset workloads against a specific domain topology, described by a <code>Subset</code> array.</p><pre><code>type Topology struct {
    // Contains the details of each subset.
    Subsets []Subset
}

type Subset struct {
    // Indicates the name of this subset, which will be used to generate
    // subset workload name prefix in the format &#x27;&lt;deployment-name&gt;-&lt;subset-name&gt;-&#x27;.
    Name string

    // Indicates the node select strategy to form the subset.
    NodeSelector corev1.NodeSelector

    // Indicates the number of the subset replicas or percentage of it on the
    // UnitedDeployment replicas.
    Replicas *intstr.IntOrString
}
</code></pre><p>The specification of the subset workload is saved in <code>Spec.Template</code>. UnitedDeployment
only supports <code>StatefulSet</code> subset workload as of now. An interesting part of <code>Subset</code>
design is that now user can specify <strong>customized Pod distribution</strong> across AZs, which is not
necessarily a uniform distribution in some cases. For example, if the AZ
utilization or capacity are not homogeneous, evenly distributing Pods may lead to Pod deployment
failure due to lack of resources. If users have prior knowledge about AZ resource capacity/usage,
UnitedDeployment can help to apply an optimal Pod distribution to ensure overall
cluster utilization remains balanced. Of course, if not specified, a uniform Pod distribution
will be applied to maximize availability.</p><h2>Customized subset rollout <code>Partitions</code></h2><p>User can update all the UnitedDeployment subset workloads by providing a
new version of subset workload template.
Note that UnitedDeployment does not control
the entire rollout process of all subset workloads, which is typically done by another rollout
controller built on top of it. Since the replica number in each <code>Subset</code> can be different,
it will be much more convenient to allow user to specify the individual rollout <code>Partition</code> of each
subset workload instead of using one <code>Partition</code> to rule all, so that they can be upgraded in the same pace.
UnitedDeployment provides <code>ManualUpdate</code> strategy to customize per subset rollout <code>Partition</code>.</p><pre><code>type UnitedDeploymentUpdateStrategy struct {
    // Type of UnitedDeployment update.
    Type UpdateStrategyType
    // Indicates the partition of each subset.
    ManualUpdate *ManualUpdate
}

type ManualUpdate struct {
    // Indicates number of subset partition.
    Partitions map[string]int32
}
</code></pre><p><img src="/img/blog/2019-11-20-uniteddeployment/uniteddeployment-1.png" alt="multi-cluster controller"/></p><p>This makes it fairly easy to coordinate multiple subsets rollout. For example,
as illustrated in Figure 1, assuming UnitedDeployment manages three subsets and
their replica numbers are 4, 2, 2 respectively, a rollout
controller can realize a canary release plan of upgrading 50% of Pods in each
subset at a time by setting subset partitions to 2, 1, 1 respectively.
The same cannot be easily achieved by using a single workload controller like <code>StatefulSet</code>
or <code>Deployment</code>.</p><h2>Multi-Cluster application management (In future)</h2><p>UnitedDeployment can be extended to support multi-cluster workload
management. The idea is that <code>Subsets</code> may not only
reside in one cluster, but also spread over multiple clusters.
More specifically, domain topology specification will associate
a <code>ClusterRegistryQuerySpec</code>, which describes the clusters that UnitedDeployment
may distribute Pods to. Each cluster is represented by a custom resource managed by a
ClusterRegistry controller using Kubernetes <a href="https://github.com/kubernetes/cluster-registry">cluster registry APIs</a>.</p><pre><code>type Topology struct {
  // ClusterRegistryQuerySpec is used to find the all the clusters that
  // the workload may be deployed to. 
  ClusterRegistry *ClusterRegistryQuerySpec
  // Contains the details of each subset including the target cluster name and
  // the node selector in target cluster.
  Subsets []Subset
}

type ClusterRegistryQuerySpec struct {
  // Namespaces that the cluster objects reside.
  // If not specified, default namespace is used.
  Namespaces []string
  // Selector is the label matcher to find all qualified clusters.
  Selector   map[string]string
  // Describe the kind and APIversion of the cluster object.
  ClusterType metav1.TypeMeta
}

type Subset struct {
  Name string

  // The name of target cluster. The controller will validate that
  // the TargetCluster exits based on Topology.ClusterRegistry.
  TargetCluster *TargetCluster

  // Indicate the node select strategy in the Subset.TargetCluster.
  // If Subset.TargetCluster is not set, node selector strategy refers to
  // current cluster.
  NodeSelector corev1.NodeSelector

  Replicas *intstr.IntOrString 
}

type TargetCluster struct {
  // Namespace of the target cluster CRD
  Namespace string
  // Target cluster name
  Name string
}
</code></pre><p>A new <code>TargetCluster</code> field is added to the <code>Subset</code> API. If it presents, the
<code>NodeSelector</code> indicates the node selection logic in the target cluster. Now
UnitedDeployment controller can distribute application Pods to multiple clusters by
instantiating a <code>StatefulSet</code> workload in each target cluster with a specific
replica number (or a percentage of total replica), as illustrated in Figure 2.</p><p><img src="/img/blog/2019-11-20-uniteddeployment/uniteddeployment-2.png" alt="multi-cluster	controller"/></p><p>At a first glance, UnitedDeployment looks more like a federation
controller following the design pattern of <a href="https://github.com/kubernetes-sigs/kubefed">Kubefed</a>,
but it isn&#x27;t. The fundamental difference is that Kubefed focuses on propagating arbitrary
object types to remote clusters instead of managing an application across clusters.
In this example, had a Kubefed style controller been used, each <code>StatefulSet</code> workload in
individual cluster would have a replica of 100. UnitedDeployment focuses more on
providing the ability of managing multiple workloads in multiple clusters on behalf
of one application, which is absent in Kubernetes community to the best of our
knowledge.</p><h2>Summary</h2><p>This blog post introduces UnitedDeployment, a new controller which helps managing
application spread over multiple domains (in arbitrary clusters).
It not only allows evenly distributing Pods over AZs,
which arguably can be more efficiently done using the new Pod Topology Spread
Constraint APIs though, but also enables flexible workload deployment/rollout and
supports multi-cluster use cases in the future.</p>]]></content>
        <author>
            <name>Fei Guo</name>
            <uri>https://github.com/Fei-Guo</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Learning Concurrent Reconciling]]></title>
        <id>learning-concurrent-reconciling</id>
        <link href="https://openkruise.io/zh/blog/learning-concurrent-reconciling"/>
        <updated>2019-11-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The concept of controller in Kubernete is one of the most important reasons that make it successful.]]></summary>
        <content type="html"><![CDATA[<p>The concept of controller in Kubernete is one of the most important reasons that make it successful.
Controller is the core mechanism that supports Kubernetes APIs to ensure the system reaches
the desired state. By leveraging CRDs/controllers and operators, it is fairly easy for
other systems to integrate with Kubernetes. </p><p>Controller runtime library and the corresponding controller tool <a href="https://book.kubebuilder.io/introduction.html">KubeBuilder</a>
are widely used by many developers to build their customized Kubernetes controllers. In Kruise project,
we also use Kubebuilder to generate scaffolding codes that implement the &quot;reconciling&quot; logic.
In this blog post, I will share some learnings from
Kruise controller development, particularly, about concurrent reconciling. </p><p>Some people may already notice that controller runtime supports concurrent reconciling.
Check for the options (<a href="https://github.com/kubernetes-sigs/controller-runtime/blob/81842d0e78f7111f0566156189806e2801e3adf1/pkg/controller/controller.go#L32">source</a>)
used to create new controller:  </p><pre><code>type Options struct {
    // MaxConcurrentReconciles is the maximum number of concurrent Reconciles which can be run. Defaults to 1.
    MaxConcurrentReconciles int

    // Reconciler reconciles an object
    Reconciler reconcile.Reconciler
}
</code></pre><p>Concurrent reconciling is quite useful when the states of the controller&#x27;s watched objects change so
frequently that a large amount of reconcile requests are sent to and queued in the reconcile queue.
Multiple reconcile loops do help drain the reconcile queue much more quickly compared to the default single
reconcile loop case. Although this is a great feature for performance, without digging into the code,
an immediate concern that a developer may raise is that will this introduce consistency issue?
i.e., is it possible that two reconcile loops handle the same object at the same time?</p><p>The answer is NO, as you may expect. The &quot;magic&quot; is enforced by the workqueue
implementation in Kubernetes <code>client-go</code>, which is used by controller runtime reconcile queue.
The workqueue algorithm (<a href="https://github.com/kubernetes/client-go/blob/a57d0056dbf1d48baaf3cee876c123bea745591f/util/workqueue/queue.go#L65">source</a>)
is demonstrated in Figure 1.</p><p><img src="/img/blog/2019-11-10-learning-concurrent-reconciling/workqueue.png" alt="workqueue"/></p><p>Basically, the workqueue uses a <code>queue</code> and two <code>sets</code> to coordinate the process of handling multiple reconciling
requests against the same object. Figure 1(a) presents the initial state of handling four reconcile requests,
two of which target the same object A. When a request arrives, the target object is first added to the <code>dirty set</code>
or dropped if it presents in <code>dirty set</code>,  and then pushed to the <code>queue</code> only if it is not presented in
<code>processing set</code>. Figure 1(b) shows the case of adding three requests consecutively.
When a reconciling loop is ready to serve a request, it gets the target object from the <code>front</code> of the queue. The
object is also added to the <code>processing set</code> and removed from the <code>dirty set</code> (Figure 1(c)).
Now if a request of the processing object arrives, the object is only added to the <code>dirty set</code>, not
to the <code>queue</code> (Figure 1(d)). This guarantees that an object is only handled by one reconciling
loop. When reconciling is done, the object is removed from the <code>processing set</code>. If the object is also
shown in the <code>dirty set</code>, it is added back to the <code>back</code> of the <code>queue</code> (Figure 1(e)).</p><p>The above algorithm has following implications:</p><ul><li>It avoids concurrent reconciling for the same object.</li><li>The object processing order can be different from arriving order even if there is only one reconciling thread.
This usually would not be a problem since the controller still reconciles to the final cluster state. However,
the out of order reconciling may cause a significant delay for a request.
<img src="/img/blog/2019-11-10-learning-concurrent-reconciling/workqueue-starve.png" alt="workqueue-starve"/>.... For example, as illustrated in
Figure 2, assuming there is only one reconciling thread and two requests targeting the same object A arrive, one of
them will be processed and object A will be added to the <code>dirty set</code> (Figure 2(b)).
If the reconciling takes a long time and during which a large number of new reconciling requests arrive,
the queue will be filled up by the new requests (Figure 2(c)). When reconciling is done, object A will be
added to the <code>back</code> of the <code>queue</code> (Figure 2(d)). It would not be handled until all the requests coming after had been
handled, which can cause a noticeable long delay. The workaround is actually simple - <strong>USE CONCURRENT RECONCILES</strong>.
Since the cost of an idle go routine is fairly small, the overhead of having multiple reconcile threads is
low even if the controller is idle. It seems that the <code>MaxConcurrentReconciles</code> value should
be overwritten to a value larger than the default 1 (CloneSet uses 10 for example).</li><li>Last but not the least, reconcile requests can be dropped (if the target exists in <code>dirty set</code>). This means
that we cannot assume that the controller can track all the object state change events. Recalling a presentation
given by <a href="https://speakerdeck.com/thockin/edge-vs-level-triggered-logic">Tim Hockin</a>, Kubernetes controller
is level triggered, not edge triggered. It reconciles for state, not for events. </li></ul><p>Thanks for reading the post, hope it helps.</p>]]></content>
        <author>
            <name>Fei Guo</name>
            <uri>https://github.com/Fei-Guo</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kruise Workload Classification Guidance]]></title>
        <id>workload-classification-guidance</id>
        <link href="https://openkruise.io/zh/blog/workload-classification-guidance"/>
        <updated>2019-10-10T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Kubernetes 目前并没有为一个应用应该使用哪个控制器提供明确的指引，这尤其不利于用户理解应用和 workload 的关系。]]></summary>
        <content type="html"><![CDATA[<p>Kubernetes 目前并没有为一个应用应该使用哪个控制器提供明确的指引，这尤其不利于用户理解应用和 workload 的关系。
比如说，用户通常知道什么时候应该用 <code>Job/CronJob</code> 或者 <code>DaemonSet</code>，这些 workload 的概念是非常明确的 -- 前者是为了任务类型的应用部署、后者则是面向需要分发到每个 node 上的长期运行 Pod。</p><p>但是另一些 workload 比如 <code>Deployment</code> 和 <code>StatefulSet</code> 之间的界限是比较模糊的。一个通过 <code>Deployment</code> 部署的应用也可以通过 <code>StatefulSet</code> 部署，<code>StatefulSet</code> 对 Pod 的 <code>OrderedReady</code> 策略并非是强制的。而且，随着 Kubernetes 社区中越来越多的自定义 controllers/operators 变的成熟，用户就越难以为自己的应用找到一个最合适的 workload 来管理，尤其是一些控制器的功能上都存在重合部分。</p><p>Kruise 尝试在两个方面来缓解这个问题：</p><ul><li>在 Kruise 中谨慎设计新的控制器，避免不必要的功能重复给用户来带困扰</li><li>为所有提供出来的 workload 控制器创建一个分类机制，方便用户更容易理解它们的使用场景。我们下面会详细描述一下，首先是 controller 命名上的规范：</li></ul><h3>Controller 命名惯例</h3><p>一个易于理解的 controller 名字对于用户选用是非常有帮助的。经过对内外部不少 Kubernetes 用户的咨询，我们决定在 Kruise 中实行以下的命名惯例（这些惯例与目前上游的 controller 命名并不冲突）：</p><ul><li><strong>Set</strong> 后缀：这类 controller 会直接操作和管理 Pod，比如 <code>CloneSet</code>, <code>ReplicaSet</code>, <code>SidecarSet</code> 等。它们提供了 Pod 维度的多种部署、发布策略。</li><li><strong>Deployment</strong> 后缀：这类 controller 不会直接地操作 Pod，它们通过操作一个或多个 <strong>Set</strong> 类型的 workload 来间接管理 Pod，比如 <code>Deployment</code> 管理 <code>ReplicaSet</code> 来提供一些额外的滚动策略，以及 <code>UnitedDeployment</code> 支持管理多个 <code>StatefulSet</code>/<code>AdvancedStatefulSet</code> 来将应用部署到不同的可用区。</li><li><strong>Job</strong> 后缀：这类 controller 主要管理短期执行的任务，比如 <code>BroadcastJob</code> 支持将任务类型的 Pod 分发到集群中所有 Node 上。</li></ul><p><strong>Set</strong>, <strong>Deployment</strong> 和 <strong>Job</strong> 都是被 Kubernetes 社区广泛接受的概念，在 Kruise 中给他们定义了明确的扩展规范。</p><p>我们能否对有相同后缀的 controller 做进一步区分呢？通常来说前缀前面的名字应该是让人能一目了然的，不过也有一些情况下很难一语描述 controller 自身的行为。可以看一下 <code>StatefulSet</code> 来源的这个 <a href="https://github.com/kubernetes/kubernetes/issues/27430">issue</a>，社区用了四个月的时间才决定用 <code>StatefulSet</code> 这个名字代替过去的 <code>PetSet</code>，尽管新名字也让人看起来比较困惑。</p><p>这个例子说明了有时候一个精心计划的名字也不一定有助于标识这个 controller。因此，Kruise 并不打算解决这个问题，而是通过以下的标准来帮助对 <strong>Set</strong> 类型的 controller 分类。</p><h3>固定 Pod 名字</h3><p><code>StatefulSet</code> 的一个独有的特性是支持一致的 Pod 网络和存储标识，这在本质上是通过固定 Pod 名字来实现的。Pod 名字可以用于标识网络和存储，因为它是 DNS record 的一部分，并且可以作为 PVC 的名字。既然 <code>StatefulSet</code> 下的 Pod 都是通过同一个模板创建出来的，为什么需要这个特性呢？一个常见的例子就是用于管理分布式一致性服务，比如 etcd 或 Zookeeper。这类应用需要知道集群构成的所有成员，并且在重建、发布后都需要保持原有的网络标识和磁盘数据。而像 <code>ReplicaSet</code>, <code>DaemonSet</code> 这类的控制器是面向无状态的，它们并不会新建 Pod 时并不会复用过去的 Pod 名字。</p><p>为了支持有状态，控制器的实现上会比较固定。<code>StatefulSet</code> 依赖于给每个 Pod 名字中加入一个序号，在扩缩容和滚动升级的时候都需要按照这个序号的顺序来执行。但这样一来，<code>StatefulSet</code> 也就无法做到另一些增强功能，比如：</p><ul><li>当缩小 replicas 时选择特定的 Pod 来删除，这个功能在跨多个可用区部署的时候会用到。</li><li>把一个存量的 Pod 接管到另一个 workload 下面（比如 <code>StatefulSet</code>）</li></ul><p>我们发现很多云原生应用并不需要这个有状态的特性来固定 Pod 名字，而 <code>StatefulSet</code> 又很难在其他方面做扩展。为了解决这个问题，Kruise 发布了一个新的控制器 <code>CloneSet</code> 来管理无状态应用，<code>CloneSet</code> 提供了对 PVC 模板的支持，并且为应用部署提供了丰富的可选策略。以下表中比较了 Advanced StatefulSet 和 CloneSet 一些方面的能力：</p><table><thead><tr><th>Features</th><th align="center">Advanced StatefulSet</th><th align="center">CloneSet</th></tr></thead><tbody><tr><td>PVC</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Pod name</td><td align="center">Ordered</td><td align="center">Random</td></tr><tr><td>Inplace upgrade</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Max unavailable</td><td align="center">Yes</td><td align="center">Yes</td></tr><tr><td>Selective deletion</td><td align="center">No</td><td align="center">Yes</td></tr><tr><td>Selective upgrade</td><td align="center">No</td><td align="center">Yes</td></tr><tr><td>Change Pod ownership</td><td align="center">No</td><td align="center">Yes</td></tr></tbody></table><p>目前对于 Kruise 用户的建议是，如果你的应用需要固定的 Pod 名字（网络和存储标识），你可以使用 <code>Advanced StatefulSet</code>，否则 <code>CloneSet</code> 应该是 <strong>Set</strong> 类型控制器的首选。</p><h3>总结</h3><p>Kruise 会为各种 workload 选择明确的名字，本文目标是能为 Kruise 用户提供选择正确 controller 部署应用的指引。
希望对你有帮助！</p>]]></content>
        <author>
            <name>Fei Guo</name>
            <uri>https://github.com/Fei-Guo</uri>
        </author>
        <author>
            <name>Siyu Wang</name>
            <uri>https://github.com/FillZpp</uri>
        </author>
    </entry>
</feed>